{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nShorç®—æ³•åœ¨å®é™…é‡å­ç¡¬ä»¶ä¸Šè¿è¡Œæ—¶ï¼Œå¦‚ä½•ç¡®ä¿é‡å­æ¯”ç‰¹çš„çŠ¶æ€åœ¨æ•´ä¸ªè®¡ç®—è¿‡ç¨‹ä¸­ä¿æŒç¨³å®šï¼Œä»¥æ»¡è¶³ç®—æ³•å¯¹é«˜ç²¾åº¦é‡å­æ€çš„è¦æ±‚ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç®—æ³•ä¸­çš„æ€å åŠ åŸç†åœ¨å¤æ‚è®¡ç®—ä»»åŠ¡é‡Œï¼Œæ€æ ·ç²¾ç¡®è°ƒæ§ä»¥å®ç°é«˜æ•ˆè¿ç®—ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nä»ä¿¡æ¯è®ºè§†è§’çœ‹ï¼Œé‡å­ç®—æ³•ç›¸æ¯”ç»å…¸ç®—æ³•ï¼Œåœ¨ä¿¡æ¯å¤„ç†çš„æé™ä¸Šæœ‰ä½•ä¸åŒï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­çº ç¼ åœ¨é‡å­ç®—æ³•åŠ é€Ÿæœºåˆ¶ä¸­æ‰®æ¼”ä½•ç§å…³é”®è§’è‰²ï¼Œå¦‚ä½•æ›´å¥½åœ°åˆ©ç”¨çº ç¼ èµ„æºï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç®—æ³•çš„è¿è¡Œè¿‡ç¨‹ä¸­ï¼Œå¦‚ä½•ç²¾å‡†æµ‹é‡é‡å­æ€ä»¥è·å–æœ‰æ•ˆè®¡ç®—ç»“æœï¼ŒåŒæ—¶é¿å…æµ‹é‡å¹²æ‰°ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né’ˆå¯¹ç‰¹å®šçš„ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œè®¾è®¡é‡å­ç®—æ³•æ—¶ï¼Œå¦‚ä½•é€‰å–åˆé€‚çš„é‡å­é—¨åºåˆ—ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç®—æ³•åœ¨å¤§æ•°æ®å¤„ç†ä¸­ï¼Œæ€æ ·åˆ©ç”¨é‡å­å¹¶è¡Œæ€§æå‡æ•°æ®æŒ–æ˜å’Œåˆ†ææ•ˆç‡ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨é‡å­è®¡ç®—ç¯å¢ƒä¸‹ï¼Œå¦‚ä½•è®¾è®¡å®‰å…¨ä¸”é«˜æ•ˆçš„åˆ†å¸ƒå¼é‡å­ç®—æ³•ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨åˆ©ç”¨Shorç®—æ³•è¿›è¡Œå®é™…çš„å¤§æ•°è´¨å› æ•°åˆ†è§£æ—¶ï¼Œå¦‚ä½•é€‰æ‹©åˆé€‚çš„é‡å­æ¯”ç‰¹ç¼–ç æ–¹å¼ï¼Œä»¥å‡å°‘å™ªå£°å’Œé€€ç›¸å¹²å¯¹è®¡ç®—ç»“æœçš„å½±å“ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\næ„å»ºé‡å­ç®—æ³•ç¼–è¯‘å™¨ï¼Œéœ€è¦è§£å†³å“ªäº›å…³é”®æŠ€æœ¯éš¾é¢˜ï¼Œä»¥å®ç°ç®—æ³•åˆ°ç¡¬ä»¶æŒ‡ä»¤çš„é«˜æ•ˆè½¬åŒ–ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç®—æ³•åœ¨é‡‘èé£é™©é¢„æµ‹å’ŒæŠ•èµ„ç»„åˆä¼˜åŒ–æ–¹é¢ï¼Œèƒ½å¸¦æ¥å“ªäº›ç‹¬ç‰¹çš„è§£å†³æ–¹æ¡ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nShorç®—æ³•ä¸­é‡å­å‚…é‡Œå¶å˜æ¢ï¼ˆQFTï¼‰å…·ä½“æ˜¯å¦‚ä½•ä¸å¤§æ•°è´¨å› æ•°åˆ†è§£ä»»åŠ¡ç²¾ç¡®è¡”æ¥çš„ï¼Œä»æ•°å­¦æ¨å¯¼å±‚é¢å¦‚ä½•è§£é‡Šè¿™ç§å…³è”ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nIn quantum image processing, we have used different image encoding methods for edge detection and binary image classification. When compared to classical process, quantum provides advantage in runtime, space complexity i.e. number of bits/qubits required for image encoding, but is not sufficient in terms of depth and width of image. With Quantum methods it is quite challenging to handle larger images as circuit design gets complex with increased number of qubits required, leading to addition of noise with inaccurate edge detection and classification results. In this project, we have used gate based quantum statevector and qasm simulator that are slower in performance which in-turn increases the training time for larger datasets and requires splitting of data into smaller sets and recombining to get higher accuracy for larger image pixel and datasets. While running real quantum may provides better performance but it is more exposed to the noise from the devices. As advancements with this projects, our team is working to analyse impact of different noise models on the quantum image encoding circuit and its results when processing smaller pixel as well as large pixel images. Our work in future will include implementing from quantum processed results for image verification with original/real-time images to reach better accuracy.\n## REFERENCES\n- [1] Yue Ruan, Xiling Xue, and Yuanxia Shen. Quantum image processing: Opportunities and challenges. Mathematical Problems in Engineering , 2021, 2021.\n- [2] Fei Yan, Abdullah M Iliyasu, and Salvador E Venegas-Andraca. A survey of quantum image representations. Quantum Information Processing , 15(1):1-35, 2016.\n- [3] Salvador E Venegas-Andraca and Sougato Bose. Storing, processing, and retrieving an image using quantum mechanics. In Eric Donkor, Andrew R. Pirich, and Howard E. Brandt, editors, Quantum Information and Computation , volume 5105, pages 137 - 147. International Society for Optics and Photonics, SPIE, 2003.\n- [4] Phuc Q Le, Fangyan Dong, and Kaoru Hirota. A flexible representation of quantum images for polynomial preparation, image compression, and processing operations. Quantum Information Processing , 10(1):63-84, 2011.\n- [5] Panchi Li, Hong Xiao, and Binxu Li. Quantum representation and watermark strategy for color images based on the controlled rotation of qubits. Quantum Information Processing , 15(11):4415-4440, 2016.\n- [6] Rabia Amin Khan. An improved flexible representation of quantum images. Quantum Information Processing , 18(7):1-19, 2019.\n- [7] Yi Zhang, Kai Lu, Yinghui Gao, and Mo Wang. Neqr: a novel enhanced quantum representation of digital images. Quantum information processing , 12(8):2833-2860, 2013.\n- [8] RiGui Zhou, WenWen Hu, GaoFeng Luo, XingAo Liu, and Ping Fan. Quantum realization of the nearest neighbor value interpolation method for ineqr. Quantum Information Processing , 17(7):1-37, 2018.\n- [9] Hai-Sheng Li, Xiao Chen, Shuxiang Song, Zhixian Liao, and Jianying Fang. A block-based quantum image scrambling for gneqr. IEEE Access , 7:138233-138243, 2019.\n- [10] Simona Caraiman and Vasile Manta. Image representation and processing using ternary quantum computing. In International Conference on Adaptive and Natural Computing Algorithms , pages 366-375. Springer, 2013.\n- [11] Hai-Sheng Li, Qingxin Zhu, Ri-Gui Zhou, Lan Song, and Xing-jiang Yang. Multi-dimensional color image storage and retrieval for a normal arbitrary quantum superposition state. Quantum Information Processing , 13(4):991-1011, 2014.\n- [12] Xi-Wei Yao, Hengyan Wang, Zeyang Liao, Ming-Cheng Chen, Jian Pan, Jun Li, Kechao Zhang, Xingcheng Lin, Zhehui Wang, Zhihuang Luo, et al. Quantum image processing and its application to edge detection: theory and experiment. Physical Review X , 7(3):031041, 2017.\n- [13] VojtË‡ ech HavlÂ´ Ä±Ë‡ek, c Antonio D. CÂ´ orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, 'Jerry M. Chow, and Jay M. Gambetta. Supervised learning with quantum-enhanced feature spaces. Nature , 567(7747):209-212, Mar 2019.\n- [14] John Francis Canny. Finding edges and lines in images. Technical report, MASSACHUSETTS INST OF TECH CAMBRIDGE ARTIFICIAL INTELLIGENCE LAB, 1983.\n- [15] FG Irwin et al. An isotropic 3x3 image gradient operator. Presentation at Stanford AI Project , 2014(02), 1968.\n- [16] Tamar Peli and David Malah. A study of edge detection algorithms. Computer graphics and image processing , 20(1):1-21, 1982.\n- [17] John Canny. A computational approach to edge detection. IEEE Transactions on pattern analysis and machine intelligence , (6):679-698, 1986.\n- [18] Hans Peter Moravec. Obstacle avoidance and navigation in the real world by a seeing robot rover . PhD thesis, Stanford University, 1980.\n- [19] Chris Harris, Mike Stephens, et al. A combined corner and edge detector. In Alvey vision conference , volume 15, pages 10-5244. Citeseer, 1988.\n- [20] Wolfgang FÂ¨ orstner and Eberhard GÂ¨ ulch. A fast operator for detection and precise location of distinct points, corners and centres of circular features. In Proc. ISPRS intercommission conference on fast processing of photogrammetric data , pages 281-305. Interlaken, 1987.\n- [21] Stephen M Smith and J Michael Brady. Susan-a new approach to low level image processing. International journal of computer vision , 23(1):45-78, 1997.\n- [22] Minakshi Banerjee and Malay K Kundu. Handling of impreciseness in gray level corner detection using fuzzy set theoretic approach. Applied Soft Computing , 8(4):1680-1691, 2008.\n- [23] Pengao Xu, Zhenxing He, Tianhui Qiu, and Hongyang Ma. Quantum image processing algorithm using edge extraction based on kirsch operator. Optics express , 28(9):12508-12517, 2020.\n- [24] Yi Zhang, Kai Lu, and YingHui Gao. Qsobel: A novel quantum image edge extraction algorithm. Science China Information Sciences , 58, 12 2014.\n- [25] Ping Fan, Ri-Gui Zhou, Wen Wen Hu, and NaiHuan Jing. Quantum image edge extraction based on laplacian operator and zero-cross method. Quantum Information Processing , 18(1):1-23, 2019.\n- [26] Yulin Ma, Hongyang Ma, and Pengcheng Chu. Demonstration of quantum image edge extration enhancement through improved sobel operator. IEEE Access , 8:210277-210285, 2020.\n- [27] Xi-Wei Yao, Hengyan Wang, Zeyang Liao, Ming-Cheng Chen, Jian Pan, Jun Li, Kechao Zhang, Xingcheng Lin, Zhehui Wang, Zhihuang Luo, and et al. Quantum image processing and its application to edge detection: Theory and experiment. Physical Review X , 7(3), Sep 2017.\n- [28] Jae-Eun Park, Brian Quanz, Steve Wood, Heather Higgins, and Ray Harishankar. Practical application improvement to quantum svm: theory to practice. arXiv preprint arXiv:2012.07725 , 2020.\n- [29] Dawid Kopczyk. Quantum machine learning for data scientists. arXiv preprint arXiv:1804.10068 , 2018.\n- [30] Iris Cong, Soonwon Choi, and Mikhail D Lukin. Quantum convolutional neural networks. Nature Physics , 15(12):1273-1278, 2019.\n- [31] Seunghyeok Oh, Jaeho Choi, and Joongheon Kim. A tutorial on quantum convolutional neural networks (qcnn). In 2020 International Conference on Information and Communication Technology Convergence (ICTC) , pages 236-239. IEEE, 2020.\n- [32] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010.\n- [33] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. CoRR , abs/1708.07747, 2017.\n- [34] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced research).\n- [35] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition, 2015.\n- [36] Jeremy Howard and Sylvain Gugger. Fastai: A layered api for deep learning. Information , 11(2):108, Feb 2020.\n- [37] Quantum edge detection - qhed algorithm on small and large images. Qiskit Documentation .\n- [38] Ruchipas Bavontaweepanya. Effect of depolarizing noise on entangled photons. In Journal of Physics: Conference Series , volume 1144, page 012047. IOP Publishing, 2018.\n## Numerical Simulation of the Time-Dependent SchrÂ¨dinger o Equation Using the Crank-Nicolson Method\n\nAdib Kabir\n\nMay 10, 2024\n\n## Abstract\nThis study presents a numerical simulation of a quantum electron confined in a 10 nm potential well, employing the Crank-Nicolson numerical technique to solve the time-dependent SchrÂ¨dinger o equation. Our results capture the evolution of the electron's wavefunction at the 2000th time step, illustrating distinct standing wave patterns and probability densities that validate quantum mechanical predictions. Additionally, both 2D and 3D simulations across multiple time steps reveal the dynamic nature of quantum superposition and interference within the well. These findings underscore the method's stability and accuracy, offering a robust tool for exploring quantum phenomena in constrained quantum systems\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Numerical_Simulation_of_the_Time-Dependent_Schrodinger_Equation_Using_the_Crank-Nicolson_Method - https://arxiv.org/abs/2410.10060\n[2] Quantum_Image_Processing - https://arxiv.org/abs/2203.01831\n[3] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[4] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­æœºå™¨å­¦ä¹ ç®—æ³•åœ¨ç‰¹å¾æå–å’Œæ¨¡å‹è®­ç»ƒé˜¶æ®µï¼Œä¸ç»å…¸æœºå™¨å­¦ä¹ æœ‰å“ªäº›æœ¬è´¨å·®å¼‚å’Œä¼˜åŠ¿ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç®—æ³•åœ¨é€šä¿¡ç½‘ç»œçš„è·¯ç”±ä¼˜åŒ–å’Œæµé‡è°ƒåº¦ä¸­ï¼Œèƒ½å®ç°æ€æ ·çš„æ€§èƒ½çªç ´ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né¢å¯¹é‡å­æ¯”ç‰¹çš„æœ‰é™å¯¿å‘½å’Œé«˜é”™è¯¯ç‡ï¼Œé‡å­ç®—æ³•çš„å®¹é”™è®¾è®¡æœ‰å“ªäº›æ–°æ€è·¯ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨é‡å­ç®—æ³•çš„ç ”ç©¶ä¸­ï¼Œå¦‚ä½•å°†Shorç®—æ³•ä¸å…¶ä»–é‡å­ç®—æ³•ï¼ˆå¦‚é‡å­æœç´¢ç®—æ³•ï¼‰ç»“åˆï¼Œä»¥è§£å†³æ›´å¤æ‚çš„ç»¼åˆæ€§é—®é¢˜ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¦‚ä½•ä»ç†è®ºä¸Šè¯æ˜é‡å­ç®—æ³•åœ¨ç‰¹å®šé—®é¢˜ä¸Šç›¸å¯¹äºç»å…¸ç®—æ³•çš„ç»å¯¹ä¼˜åŠ¿ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­æœç´¢ç®—æ³•ï¼ˆå¦‚Groverç®—æ³•ï¼‰ç›¸æ¯”ç»å…¸æœç´¢ç®—æ³•ï¼Œåœ¨å®é™…åº”ç”¨åœºæ™¯ï¼ˆå¦‚æ•°æ®åº“æœç´¢ï¼‰ä¸­èƒ½å¸¦æ¥å¤šå¤§ç¨‹åº¦çš„æ•ˆç‡æå‡ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¦‚ä½•è®¾è®¡é‡å­ç®—æ³•ä»¥è§£å†³NPå®Œå…¨é—®é¢˜ï¼Œç›®å‰é¢ä¸´çš„ä¸»è¦å›°éš¾æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nShorç®—æ³•åœ¨é¢å¯¹å…·æœ‰ç‰¹æ®Šæ•°å­¦ç»“æ„çš„å¤§æ•°ï¼ˆå¦‚æ¢…æ£®æ•°ï¼‰æ—¶ï¼Œæ˜¯å¦å­˜åœ¨é’ˆå¯¹æ€§çš„ä¼˜åŒ–ç­–ç•¥æ¥æé«˜åˆ†è§£æ•ˆç‡ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¶…å¯¼é‡å­æ¯”ç‰¹ï¼ˆTransmonï¼‰ä¸­çº¦ç‘Ÿå¤«æ£®ç»“çš„éçº¿æ€§ç”µæ„Ÿç‰¹æ€§åœ¨ä¸åŒæ¸©åº¦å’Œç£åœºç¯å¢ƒä¸‹ï¼Œä¼šå‘ç”Ÿæ€æ ·çš„å˜åŒ–ï¼Œå¯¹é‡å­æ¯”ç‰¹çš„ç¨³å®šæ€§æœ‰ä½•å½±å“ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨è¶…å¯¼é‡å­æ¯”ç‰¹çš„åˆ¶å¤‡è¿‡ç¨‹ä¸­ï¼Œå¦‚ä½•é™ä½æ‚è´¨å’Œç¼ºé™·å¯¹çº¦ç‘Ÿå¤«æ£®ç»“æ€§èƒ½çš„å¹²æ‰°ï¼Œä»è€Œæé«˜é‡å­æ¯”ç‰¹çš„è´¨é‡ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¶…å¯¼é‡å­æ¯”ç‰¹ä¸å‘¨è¾¹ç”µè·¯çš„è€¦åˆæ–¹å¼å¯¹å…¶é‡å­æ€çš„æ“æ§ç²¾åº¦å’Œé€€ç›¸å¹²æ—¶é—´æœ‰ä½•å½±å“ï¼Œå¦‚ä½•ä¼˜åŒ–è¿™ç§è€¦åˆè®¾è®¡ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå½“å¤šä¸ªè¶…å¯¼é‡å­æ¯”ç‰¹ç»„æˆé‡å­æ¯”ç‰¹é˜µåˆ—æ—¶ï¼Œå¦‚ä½•æœ‰æ•ˆæŠ‘åˆ¶æ¯”ç‰¹é—´çš„ä¸²æ‰°ï¼Œç¡®ä¿æ¯ä¸ªæ¯”ç‰¹èƒ½ç‹¬ç«‹ä¸”å‡†ç¡®åœ°æ‰§è¡Œé‡å­é—¨æ“ä½œï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nä»é‡å­çº é”™çš„è§’åº¦å‡ºå‘ï¼Œè¶…å¯¼é‡å­æ¯”ç‰¹çš„ç‰©ç†ç‰¹æ€§å¯¹æ„å»ºæœ‰æ•ˆçš„é‡å­çº é”™ç æœ‰å“ªäº›ä¼˜åŠ¿å’ŒæŒ‘æˆ˜ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨å¤§è§„æ¨¡è¶…å¯¼é‡å­è®¡ç®—èŠ¯ç‰‡çš„åˆ¶é€ è¿‡ç¨‹ä¸­ï¼Œå¦‚ä½•ä¿è¯ä¼—å¤šçº¦ç‘Ÿå¤«æ£®ç»“çš„ä¸€è‡´æ€§ï¼Œä»¥å®ç°èŠ¯ç‰‡æ€§èƒ½çš„ç¨³å®šå’Œå¯é ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå½“è¶…å¯¼é‡å­æ¯”ç‰¹ç”¨äºé‡å­æ¨¡æ‹Ÿä»»åŠ¡æ—¶ï¼Œå¦‚ä½•åˆ©ç”¨å…¶èƒ½çº§ç»“æ„ç‰¹æ€§é«˜æ•ˆæ¨¡æ‹Ÿå¤æ‚çš„é‡å­ç³»ç»Ÿï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¶…å¯¼é‡å­æ¯”ç‰¹å¯¹ä½æ¸©ç¯å¢ƒçš„ä¸¥æ ¼è¦æ±‚å¸¦æ¥äº†é«˜æ˜‚çš„åˆ¶å†·æˆæœ¬ï¼Œæœ‰å“ªäº›æ–°å‹åˆ¶å†·æŠ€æœ¯æˆ–ä¼˜åŒ–ç­–ç•¥å¯é™ä½è¿™ä¸€æˆæœ¬ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¶…å¯¼é‡å­æ¯”ç‰¹ä¸å…‰å­çš„æ¥å£æŠ€æœ¯å‘å±•ç°çŠ¶å¦‚ä½•ï¼Œå¦‚ä½•å®ç°é«˜æ•ˆçš„è¶…å¯¼ - å…‰å­ç›¸äº’è½¬æ¢ï¼Œä»¥æ‹“å±•é‡å­ä¿¡æ¯çš„ä¼ è¾“å’Œå¤„ç†æ–¹å¼ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¶…å¯¼é‡å­æ¯”ç‰¹åœ¨é‡å­é€šä¿¡é¢†åŸŸæœ‰å“ªäº›æ½œåœ¨åº”ç”¨ï¼Œå…¶ç‰©ç†ç‰¹æ€§å¦‚ä½•æ”¯æŒé‡å­å¯†é’¥åˆ†å‘ã€é‡å­éšå½¢ä¼ æ€ç­‰ä»»åŠ¡ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¶…å¯¼é‡å­æ¯”ç‰¹çš„èƒ½çº§ç»“æ„å¯¹é‡å­æ¯”ç‰¹çš„åˆå§‹åŒ–å’Œæµ‹é‡ç²¾åº¦æœ‰ä½•å½±å“ï¼Œå¦‚ä½•æ”¹è¿›æµ‹é‡æŠ€æœ¯ä»¥æé«˜æµ‹é‡çš„å‡†ç¡®æ€§ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nç¦»å­é˜±é‡å­æ¯”ç‰¹åœ¨å®ç°å¤šæ¯”ç‰¹çº ç¼ æ—¶ï¼Œå¦‚ä½•æœ‰æ•ˆå‡å°‘ç¦»å­é—´çš„åº“ä»‘ç›¸äº’ä½œç”¨å¹²æ‰°ï¼Œä»è€Œæé«˜çº ç¼ ä¿çœŸåº¦ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç‚¹é‡å­æ¯”ç‰¹åœ¨ä¸å¤–éƒ¨ç”µè·¯è€¦åˆè¿‡ç¨‹ä¸­ï¼Œæ€æ ·ä¼˜åŒ–è€¦åˆæ–¹å¼ä»¥é™ä½å™ªå£°å¼•å…¥ï¼Œç¡®ä¿é‡å­æ¯”ç‰¹çš„é«˜ä¿çœŸåº¦æ“ä½œï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\næ‹“æ‰‘é‡å­æ¯”ç‰¹å‡­å€Ÿä½•ç§ç‹¬ç‰¹çš„ç‰©ç†æ€§è´¨å±•ç°å‡ºå¼ºå¤§çš„æŠ—å™ªå£°èƒ½åŠ›ï¼Œç›®å‰å®ç°æ‹“æ‰‘é‡å­æ¯”ç‰¹é¢ä¸´å“ªäº›æŠ€æœ¯æŒ‘æˆ˜ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåŸºäºé‡‘åˆšçŸ³æ°® - ç©ºä½ï¼ˆNVï¼‰è‰²å¿ƒçš„é‡å­æ¯”ç‰¹ï¼Œåœ¨å®¤æ¸©ç¯å¢ƒä¸‹å¦‚ä½•è¿›ä¸€æ­¥æé«˜å…¶é‡å­æ€çš„ç›¸å¹²æ—¶é—´ï¼Œæ‹“å±•å…¶å®é™…åº”ç”¨åœºæ™¯ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç¡¬ä»¶ä¸­çš„é‡å­é—¨æ“ä½œç²¾åº¦å—å“ªäº›å› ç´ åˆ¶çº¦ï¼Œå¦‚ä½•é€šè¿‡æ”¹è¿›ç¡¬ä»¶è®¾è®¡å’Œæ§åˆ¶ç®—æ³•æ¥æå‡æ“ä½œç²¾åº¦ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç¡¬ä»¶ä¸ç»å…¸æ§åˆ¶ç”µè·¯çš„æ¥å£è®¾è®¡é¢ä¸´å“ªäº›æŒ‘æˆ˜ï¼Œå¦‚ä½•å®ç°é«˜æ•ˆã€ä½å™ªå£°çš„é‡å­ - ç»å…¸æ¥å£ï¼Œä¿éšœé‡å­è®¡ç®—ç³»ç»Ÿçš„ç¨³å®šè¿è¡Œï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨é‡å­æ¨¡æ‹Ÿåº”ç”¨ä¸­ï¼Œå¦‚ä½•æ ¹æ®æ¨¡æ‹Ÿå¯¹è±¡çš„ç‰¹æ€§é€‰æ‹©æœ€åˆé€‚çš„é‡å­ç¡¬ä»¶å¹³å°ï¼Œä»¥å®ç°é«˜æ•ˆã€ç²¾å‡†çš„æ¨¡æ‹Ÿï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå…‰é‡å­æ¯”ç‰¹åœ¨æ„å»ºè¿œè·ç¦»é‡å­é€šä¿¡ç½‘ç»œæ–¹é¢å…·æœ‰å“ªäº›ä¼˜åŠ¿ï¼Œç›®å‰åœ¨å…‰é‡å­æ¯”ç‰¹çš„ç”Ÿæˆã€ä¼ è¾“å’Œæ“æ§è¿‡ç¨‹ä¸­å­˜åœ¨å“ªäº›æŠ€æœ¯éš¾é¢˜ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç¡¬ä»¶çš„é‡å­çº é”™èƒ½åŠ›ä¸ç¡¬ä»¶æœ¬èº«çš„ç‰©ç†ç‰¹æ€§ç´§å¯†ç›¸å…³ï¼Œå¦‚ä½•ç»“åˆç¡¬ä»¶ç‰¹æ€§è®¾è®¡é’ˆå¯¹æ€§å¼ºã€æ•ˆç‡é«˜çš„é‡å­çº é”™æ–¹æ¡ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨é‡å­æ€åˆ¶å¤‡çš„åˆå§‹åŒ–é˜¶æ®µï¼Œä¹Ÿå°±æ˜¯ä»âˆ£0âŸ©âŠ—âˆ£0âŸ©å¼€å§‹ï¼Œå®éªŒé‡Œæ€æ ·ä¿éšœåˆå§‹æ€çš„çº¯åº¦å‘¢ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡‡ç”¨ Hadamard é—¨ç”Ÿæˆå åŠ æ€æ—¶ï¼Œæ€æ ·å‡å°å› é—¨æ“ä½œæ—¶é—´è¿‡é•¿è€Œå¼•å‘çš„é€€ç›¸å¹²é—®é¢˜ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå®éªŒä¸­ï¼Œæ€æ ·å€ŸåŠ©éšæœºåŸºå‡†æµ‹è¯•æ¥æ ¡å‡† CNOT é—¨çš„æ“ä½œè¯¯å·®ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåˆ¶å¤‡ Bell æ€æ—¶ï¼Œæ€æ ·é€šè¿‡åŠ¨æ€è§£è€¦æŠ€æœ¯æ¥æŠ‘åˆ¶ç¯å¢ƒå™ªå£°çš„å½±å“ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\næ€æ ·åˆ©ç”¨é‡å­æ€å±‚ææˆåƒæ¥é‡åŒ– Bell æ€çš„çº ç¼ ç¨‹åº¦ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè´å°”ä¸ç­‰å¼çš„å®éªŒéªŒè¯ä¸­ï¼Œå¦‚ä½•å¤„ç†å±€åŸŸæ€§æ¼æ´å’Œæ¢æµ‹æ¼æ´ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå®éªŒæ•°æ®ä¸­ï¼Œç»å…¸å™ªå£°å’Œé‡å­å™ªå£°åœ¨ç»Ÿè®¡ç‰¹æ€§ä¸Šæœ‰ä½•åŒºåˆ«ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¤šå…‰å­å¹²æ¶‰å®éªŒé‡Œï¼Œæ€æ ·ä¿è¯å•å…‰å­æºçš„ä¸å¯åŒºåˆ†æ€§ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nT - carbon çš„æ‹“æ‰‘ç‰¹æ€§å¯¹é‡å­æ¯”ç‰¹çš„ç›¸å¹²æ—¶é—´ä¼šäº§ç”Ÿæ€æ ·çš„å½±å“ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nWe are going to use the default PauliNet architecture and change the basis set to the correlation-consistent family [60], starting from cc-pvdz to cc-pv5z. The first step is to define a Molecule object (for example named LiH ) with the geometry of LiH at an internuclear distance of 3 0141132 Bohr, and a total zero . charge and spin. Then, the PauliNet neural network can be initialized for a given basis set, say ccpvdz, from a Hartree-Fock calculation using the function from hf(LiH, basis='cc-pvdz') , meaning that the ansatz contains a single Slater determinant (cfr. Equation (33)) and uses the HF orbitals. After initialization, the network can be trained using the function train(net) , where net is the neural network object returned from the initialization procedure. This is the most expensive part of the calculation, however, the training parameters can be slightly modified to decrease the computation time, and still obtain reasonably optimized network weights (with an uncertainty of around 1 m E h ). We suggest you to use n steps = 500 , batch size = 500 and epoch size = 20 . The last step to obtain the ground state energy of LiH is to call the function evaluate(net) . Similarly to train(net) , evaluate(net) accepts optional parameters defining the number of Monte Carlo sweeps and the length of the Markov chain sampled at each step. For these two, we suggest the following values, n steps = 400 and sample size\n= 800 . Save the obtained energy and the estimated error, and repeat the same process for the other basis sets. The choice of training parameters was such that the optimization does not take too long time. If you want to investigate the effects of the training procedure on the final energy and uncertainty, as an advanced exercise you can modify the values of n steps and batch size in the train(net) function (hint: modify one value at a time to understand their role).\n## 3.2.2 CCSD(T) calculations\nIn this part we are going to perform CCSD(T) calculations in combination with the four basis sets used above. You can use PySCF for performing these calculations, and they should take significantly less time than the PauliNet ones. PySCF has a pretty extensive user guide available online at https://pyscf.org/, with many examples. We suggest you to have a look at it if you get stuck at any point. The first step is again to define the lithium hydride molecule, this time in a data-structure that PySCF understands. This can be done with the function gto.M(...) , which accepts a number of arguments similar to the construction of the Molecule object for the DeepQMC package. Then, you can create a restricted HF instance with rhf = scf.RHF(mol) , where mol is the molecule you just created (hint: make sure to set the correct basis set with mol.basis = 'cc-pvdz' and build it with mol.build() ). The rhf object can be used to create the coupled cluster instance with cc = cc.CCSD(rhf) . The energy for each method can then be obtained by calling .kernel() on the HF and coupled cluster objects, and .ccsd t() for the perturbative triples correction. Save all these energies and repeat the process for all basis sets. If you have a powerful computer, as an additional exercise you can try to compute the full CI energy, however, you will probably be able to get it at most with the triple zeta basis set (hint: for such a small molecule, the CCSD(T) and FCI energies are very similar).\n## 3.2.3 Comparison of PauliNet and CCSD(T)\n- [21] T. Skovhus, T. Olsen, Dynamic transverse magnetic susceptibility in the projector augmented-wave method: Application to Fe, Ni, and Co, Phys. Rev. B 103 (2021) 245110.\n- [22] F. Aryasetiawan, K. Karlsson, Phys. Rev. B 60 (1999) 7419.\n- [23] K. Karlsson, F. Aryasetiawan, Phys. Rev. B 62 (2000) 3006.\n- [24] T. Kotani, M. van Schilfgaarde, J. Phys.: Condens. Matter 20 (2008) 295214.\n- [25] S Â¸ aÂ¸ioË˜lu, s g A. Schindlmayr, C. Friedrich, F. Freimuth, S.BlÂ¨gel, Phys. Rev. B 81 (2010) 054434. u\n- [26] M. MÂ¨ uller, C. Friedrich, S. BlÂ¨gel, Phys. Rev. B 94 (2016) 064433. u\n- [27] E. Runge, E. Gross, Phys. Rev. Lett. 52 (1984) 997.\n- [28] M. A. L. Marques, N. T. Maitra, F. M. S. Nogueira, E. K. U. Gross, A. Rubio (Eds.), Fundamentals of Time-Dependent Density Functional Theory, Vol. 837, Lecture Notes in Physics, Springer-Verlag, Berlin Heidelberg, 2012.\n- [29] S. Baroni, R. Gebauer, The Liouville-Lanczos Approach to Time-Dependent Density-Functional (Perturbation) Theory, Ref. [28], chapter 19, p. 375-390.\n- [30] D. Rocca, R. Gebauer, Y. Saad, S. Baroni, J. Chem. Phys. 128 (2008) 154105.\n- [31] I. Timrov, N. Vast, R. Gebauer, S. Baroni, Phys. Rev. B 88 (2013) 064301, ibid. 91 , 139901 (2015).\n- [32] S. Baroni, P. Giannozzi, A. Testa, Green's-function approach to linear response in solids, Phys. Rev. Lett. 58 (1987) 1861.\n- [33] S. Baroni, S. de Gironcoli, A. D. Corso, P. Giannozzi, Phonons and related crystal properties from densityfunctional perturbation theory, Rev. Mod. Phys. 73 (2) (2001) 515.\n- [34] O. MalcioiË˜lu, R. Gebauer, D. Rocca, S. Baroni, Comput. Phys. Commun. 182 (2011) 1744. g\n- [35] X. Ge, S. J. Binnie, D. Rocca, R. Gebauer, S. Baroni, turboTDDFT 2.0 - Hybrid functionals and new algorithms within time-dependent density-functional perturbation theory, Comput. Phys. Commun. 185 (2014) 2080.\n- [36] I. Timrov, N. Vast, R. Gebauer, S. Baroni, Comput. Phys. Commun. 196 (2015) 460.\n- [37] I. Timrov, M. Markov, T. Gorni, M. Raynaud, O. Motornyi, R. Gebauer, S. Baroni, N. Vast, Phys. Rev. B 95 (2017) 094301.\n- [38] O. Motornyi, N. Vast, I. Timrov, O. Baseggio, S. Baroni, A. Dal Corso, Phys. Rev. B 102 (2020) 035156.\n- [39] The GNU General Public License: http://www.gnu.org/licenses/gpl.html .\n- [40] P. Giannozzi, S. Baroni, N. Bonini, M. Calandra, R. Car, C. Cavazzoni, D. Ceresoli, G. Chiarotti, M. Cococcioni, I. Dabo, A. Dal Corso, S. De Gironcoli, S. Fabris, G. Fratesi, R. Gebauer, U. Gerstmann, C. Gougoussis, A. Kokalj, M. Lazzeri, L. Martin-Samos, N. Marzari, F. Mauri, R. Mazzarello, S. Paolini, A. Pasquarello, L. Paulatto, C. Sbraccia, S. Scandolo, G. Sclauzero, A. Seitsonen, A. Smogunov, P. Umari, R. Wentzcovitch, Quantum ESPRESSO: A modular and open-source software project for quantum simulations of materials, J. Phys.: Condens. Matter 21 (2009) 395502.\n- [41] P. Giannozzi, O. Andreussi, T. Brumme, O. Bunau, M. Buongiorno Nardelli, M. Calandra, R. Car, C. Cavazzoni, D. Ceresoli, M. Cococcioni, N. Colonna, I. Carnimeo, A. Dal Corso, S. de Gironcoli, P. Delugas, R. A. DiStasio Jr., A. Ferretti, A. Floris, G. Fratesi, G. Fugallo, R. Gebauer, U. Gerstmann, F. Giustino, T. Gorni, J. Jia, M. Kawamura, H.-Y. Ko, A. Kokalj, E. KÂ¨Â¸ cÂ¨kbenli, M. Lazzeri, M. Marsili, N. Marzari, F. Mauri, u u N. L. Nguyen, H.-V. Nguyen, A. Otero-de-la Rosa, L. Paulatto, S. PoncÂ´, D. Rocca, R. Sabatini, B. Santra, e M. Schlipf, A. Seitsonen, A. Smogunov, I. Timrov, T. Thonhauser, P. Umari, N. Vast, S. Baroni, Advanced capabilities for materials modelling with Quantum ESPRESSO, J. Phys.: Condens. Matter 29 (2017) 465901.\n- [42] P. Giannozzi, O. Baseggio, P. Bonf` a, D. Brunato, R. Car, I. Carnimeo, C. Cavazzoni, S. de Gironcoli, P. Delugas, F. Ferrari Ruffino, A. Ferretti, N. Marzari, I. Timrov, A. Urru, S. Baroni, Quantum ESPRESSO toward the exascale, J. Chem. Phys. 152 (2020) 154105.\n- [43] O. Halpern, M. Johnson, On the Magnetic Scattering of Neutrons, Phys. Rev. 55 (1939) 898.\n- [44] M. Blume, Polarization Effects in the Magnetic Elastic Scattering of Slow Neutrons, Phys. Rev. 130 (1963) 1670.\n- [45] W. Jones, N. H. March, Theoretical solid state physics, Volume 1, Courier Corporation, 1985.\n- [46] T. Gorni, I. Timrov, S. Baroni, Spin dynamics from time-dependent density functional perturbation theory, Eur. Phys. J. B 91 (2018) 249.\n- [47] T. Gorni, Spin-fluctuation spectra in magnetic systems: a novel approach based on tddft, Ph.D. thesis, Scuola Internazionale Superiore di Studi Avanzati (SISSA), Trieste, Italy (2016, http://hdl.handle.net/20.500. 11767/43342 ).\n- [48] We use a hat ' Ë† ' on top of letters to indicate operators (e.g. Ë† ), while these same operators in the coordinate V representation are written without the hat and with the explicit dependence on the position vector r [e.g. V ( r )]. Moreover, we use a tilde ' Ëœ ' to indicate a Fourier transform of various quantities from the time domain [e.g. V ( )] t to the frequency domain [e.g. Ëœ ( V Ï‰ )]. A combination of these two notations is often used in this work.\n- [49] With the upper case letter we denote a 2 Ã— 2 matrix potential, while with the lower case letter we denote scalar potentials.\n- [50] L. Kleinman, Phys. Rev. B 21 (1980) 2630.\n- [51] G. Bachelet, SchlÂ¨ter, Phys. Rev. B 25 (1982) 2103. u\n- [52] G. Bachelet, D. Hamann, SchlÂ¨ter, Phys. Rev. B 26 (1982) 4199. u\n- [53] L. Hemstreet, C. Fong, J. Nelson, Phys. Rev. B 47 (1993) 4238.\n- [54] D. Ceresoli, U. Gerstmann, A. Seitsonen, F. Mauri, Phys. Rev. B 81 (2010) 060409(R).\n- [55] N. Ashcroft, N. Mermin, Solid State Physics, Saunders College Publishing, Philadelphia, 1976.\n- [56] A. Dal Corso, Phys. Rev. B 82 (2010) 075116.\n- [57] We note that in the second term of Eq. (9) we symbolically mean a scalar product, while in the second term of Eq. (10) we symbolically mean a matrix-vector multiplication.\n- [58] These relations are a consequence of the fact that chargeand magnetization-density responses are real functions in space and time.\n- [59] N. Singh, P. Elliott, T. Nautiyal, J. K. Dewhurst, S. Sharma, Phys. Rev. B 99 (2019) 035151.\n- [60] S. Lehtola, M. Marques, Many recent density functionals are numerically unstable, arXiv:2206.14062 (2022).\n- [61] J. Sun, A. Ruzsinszky, J. Perdew, Phys. Rev. Lett. 115 (2015) 036402.\n- [62] M. Ekholm, D. Gambino, H. JÂ¨ onsson, F. TasnÂ´di, B. Alling, I. Abrikosov, Assessing the SCAN functional a for itinerant electron ferromagnets, Phys. Rev. B 98 (2018) 094413.\n- [63] F. Tran, G. Baudesson, J. Carrete, G. Madsen, P. Blaha, K. Schwarz, D. Singh, Shortcomings of meta-GGA functionals when describing magnetism, Phys. Rev. B 102 (2020) 024407.\n- [64] T. Skovhus, T. Olsen, H. Ronnow, arXiv:2110.07282 (2022).\n- [65] T. Skovhus, T. Olsen, arXiv:2203.04796 (2022).\n- [66] M. Gokhale, A. Ormeci, D. Mills, Phys. Rev. B 46 (1992) 8978.\n- [67] Y. Saad, Iterative Methods for Sparse Linear Systems, 2nd Edition, SIAM, Philadelphia, 2003.\n- [68] M. GrÂ¨ uning, A. Marini, X. Gonze, Comput. Math. Sci. 50 (2011) 2148.\n- [69] A. Mostafazadeh, Pseudo-Hermiticity versus PT symmetry: The necessary condition for the reality of the spectrum of a non-Hermitian Hamiltonian, J. Math. Phys. 43 (2002) 205.\n- [70] GNU Autoconf: https://www.gnu.org/software/autoconf .\n- [71] CMake is an open-source, cross-platform family of tools designed to build, test and package software: https: //cmake.org/ .\n- [72] Message passing interface forum, Int. J. Supercomput. Appl. 8 (1994) 159.\n- [73] http://theossrv1.epfl.ch/Main/Pseudopotentials .\n- [74] D. Soriano, M. I. Katsnelson, J. FernÂ´ndez-Rossier, Magnetic two-dimensional chromium trihalides: A theoa retical perspective, Nano Letters 20 (9) (2020) 6225-6234.\n- [75] T. Gorni, O. Baseggio, P. Delugas, S. Baroni, I. Timrov, turboMagnon - A code for the simulation of spin-wave spectra using the Liouville-Lanczos approach to time-dependent density-functional perturbation theory, Materials Cloud Archive 2022.89 (2022), doi: 10.24435/materialscloud:6j-kd. doi:10.24435/materialscloud: 6j-kd .\n- URL https://archive.materialscloud.org/record/2022.89\n- [76] J. Goldstone, A. Salam, S. Weinberg, Broken symmetries, Phys. Rev. 127 (1962) 965-970.\n- [77] H. Watanabe, H. Murayama, Unified description of nambu-goldstone bosons without lorentz invariance, Phys. Rev. Lett. 108 (2012) 251602.\n- [78] P. Delugas, O. Baseggio, I. Timrov, S. Baroni, T. Gorni, Magnon-phonon interactions open a gap at the Dirac point in the spin-wave spectra of CrI 3 2D magnets, submitted (arXiv:2203.01120) (2021).\n- [79] L. Chen, J.-H. Chung, B. Gao, T. Chen, M. B. Stone, A. I. Kolesnikov, Q. Huang, P. Dai, Topological spin excitations in honeycomb ferromagnet CrI , Phys. Rev. X 8 (4) (2018) 041028. 3\n- [80] L. Chen, J.-H. Chung, T. Chen, C. Duan, A. Schneidewind, I. Radelytskyi, D. J. Voneshen, R. A. Ewings, M. B. Stone, A. I. Kolesnikov, B. Winn, S. Chi, R. A. Mole, D. H. Yu, B. Gao, P. Dai, Magnetic anisotropy in ferromagnetic CrI 3 , Phys. Rev. B 101 (2020) 134418.\n- [81] L. Del Re, A. Toschi, Dynamical vertex approximation for many-electron systems with spontaneously broken su(2) symmetry, Phys. Rev. B 104 (2021) 085120.\n- [82] G. Giuliani, G. Vignale, Quantum theory of the electron liquid, Cambridge university press, 2005.\n- [83] Description of the 'Galileo100' HPC cluster at CINECA: https://www.hpc.cineca.it/hardware/ galileo100 .\n- [84] H. Monkhorst, J. Pack, Special points for Brillouin-zone integrations, Phys. Rev. B 13 (1976) 5188.\n- [85] The latest development version of the Quantum ESPRESSO distribution can be downloaded from https: //gitlab.com/QEF/q-e .\n- [86] The official release of the Quantum ESPRESSO distribution can be downloaded from https://www. quantum-espresso.org .\n## Molecular property prediction with photonic chip-based machine learning\nHui Zhang, 1, âˆ— Jonathan Wei Zhong Lau, 2, âˆ— Lingxiao Wan, 3 Liang Shi, 4 Yuzhi Shi, 5 Hong Cai, 6 Xianshu Luo, 7 Guo-Qiang Lo, 7 Chee-Kong Lee, 8, â€  Leong Chuan Kwek, 3,9,10,11, â€  and Ai Qun Liu 3, â€ \nIn P. Smolensky (1990), the author suggests using a representation based on tensor product :   Tensor   Product   Representation   (TPR),   to   capture   syntactic bindings across sentences. [49, 50] Tensor product is here understood as the Kronecker product, denoted by . Given two matrices A, B we define A B to be âŠ— âŠ— the block matrix where every element of A is multiplied by B (Fig. 2.1). TPR is a structure where every unit of a sentence can be part of the representation of every constituent. It can be compositionally encoded from the numerical vectors representing the composing words, and hence offers the ideal framework to build-up a structure to embed not only words, but also sentences.\n$$\\begin{array} { c c c } a _ { 1 1 } B & \\cdots & a _ { 1 n } B \\\\ \\vdots & \\ddots & \\vdots \\\\ a _ { m 1 } B & \\cdots & a _ { m n } B \\end{array}$$\nBased on Lambek's pregroup algebra, in Mehrnoosh et al. (2010), the authors introduce the CSC algorithm, which develops another implementation of tensor based representation of the meaning of a sentence. [34] This algorithm can be implemented on a quantum computer. Let the linear map Î£âŸ¨ ii| (Fig. 2.2), which is the sum over all the basis vectors of the space N. We call this linear map a cap . It formally describes the state of log  EPR pairs (a generalization of n quantum entanglement). If the basis is of size n and is orthonormal, the cap can simply be thought of as a row vector of size n 2 , filled of 0, and valued 1 at the positions  ii|. The steps of the CSC algorithm are detailed in Fig. 2.3. âŸ¨\n$$\\sum _ { i } \\langle i | \\colon =$$\n\nFig. 2.2 (Zeng &amp; Coecke, 2016) : Definition of a cap\n- 1 Compute the tensor product words Wo wk in the order that each word appears in the sentence\n- 2 Construct a linear map that represents the grammatical type reduction by the vectors with the appropriate caps. For example, given that the pregroup type reduction of a nounhransitive verblnoun sentence is:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] A_photonic_chip-based_machine_learning_approach_for_the_prediction_of_molecular_properties - https://arxiv.org/abs/2203.02285\n[2] A_gentle_introduction_to_Quantum_Natural_Language_Processing - https://arxiv.org/abs/2202.11766\n[3] turboMagnon_--_A_code_for_the_simulation_of_spin-wave_spectra_using_the_Liouville-Lanczos_approach_to_time-dependent_density-functional_perturbation_theory - https://arxiv.org/abs/2203.01120\n[4] Machine_Learning_Wavefunction - https://arxiv.org/abs/2202.13916\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nç¡¼æºæ‚é‡‘åˆšçŸ³çš„çº³ç±³ç»“æ„æ˜¯å¦ä¼šå¯¹é‡å­é™åŸŸæ•ˆåº”é€ æˆå½±å“ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\näºŒç»´ææ–™çš„èŒƒå¾·åå¼‚è´¨ç»“æ˜¯å¦é€‚åˆç”¨äºæ„å»ºå›ºæ€é‡å­æ¯”ç‰¹ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nææ–™çš„å£°å­è°±ä¼šå¦‚ä½•å½±å“é‡å­æ¯”ç‰¹çš„å¼›è±«è¿‡ç¨‹ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç‚¹ç³»ç»Ÿä¸­ï¼Œæ€æ ·é€šè¿‡æ …æç”µå‹æ¥ç²¾ç¡®æ§åˆ¶é‡å­æ¯”ç‰¹çš„è€¦åˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nä¸­æ€§åŸå­é˜µåˆ—å®éªŒé‡Œï¼Œå¦‚ä½•å®ç°é«˜å¯†åº¦çš„çº ç¼ æ€åˆ¶å¤‡ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¶…å¯¼é‡å­ç”µè·¯ä¸­ï¼Œæ€æ ·é€šè¿‡è„‰å†²æ•´å½¢æ¥ä¼˜åŒ–é—¨æ“ä½œçš„ä¿çœŸåº¦ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nç¦»å­é˜±å®éªŒä¸­ï¼Œå¦‚ä½•æŠ‘åˆ¶å› æ¿€å…‰ç›¸ä½å™ªå£°å¯¼è‡´çš„é€€ç›¸å¹²ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¼€æ”¾é‡å­ç³»ç»Ÿçš„ä¸»æ–¹ç¨‹æ¨¡æ‹Ÿæ€æ ·ä¸å®éªŒæ•°æ®è¿›è¡Œæ¯”å¯¹ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­çº é”™ç çš„ç†è®ºæé™åœ¨å®éªŒä¸­æ˜¯å¦å®¹æ˜“è¾¾åˆ°ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\næœºå™¨å­¦ä¹ èƒ½å¦ç”¨äºé¢„æµ‹æ–°å‹é‡å­ææ–™çš„çº ç¼ ç‰¹æ€§ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­è®¡ç®—çš„èµ„æºä¼°ç®—æ€æ ·ä¸å…·ä½“çš„ç¡¬ä»¶æ¶æ„ç›¸ç»“åˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç çš„äºŒç»´ç½‘æ ¼æ‹“æ‰‘ç»“æ„å¦‚ä½•å®ç°å®¹é”™çº é”™ï¼Ÿè¾¹ç•Œæ¡ä»¶ï¼ˆå¦‚å¼€æ”¾è¾¹ç•Œä¸å‘¨æœŸè¾¹ç•Œï¼‰å¯¹çº é”™æ€§èƒ½æœ‰ä½•å½±å“ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né€»è¾‘æ“ä½œç¬¦\\(\\overline{X} = \\prod_{i} X_i\\)çš„æ„é€ å¦‚ä½•ä¿è¯å¯¹ç‰©ç†æ¯”ç‰¹é”™è¯¯çš„å…ç–«æ€§ï¼Ÿå…¶å‡ ä½•æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTheorem 7 Fix an arbitrary ordering of all contexts and list them all jointly as L= ( L , . . . , L 1 t ) , where each L i is a vertex; the ordering of vertices inside each hyperedge is also arbitrary. Impose a total order â‰º on the set of vertices. Let M be a valid Gram matrix, let Î± : V â†’ Z 2 k 2 be a valid assignment respecting M for some k âˆˆ Z â‰¥ 0 , and let Î± : V â†’ P k be the corresponding k -qubit assignment. Then Î± is a magic assignment if and only if\n$$\\sum _ { 1 \\leq i < j \\leq t, \\ L _ { i } \\succ L _ { j } } M _ { L _ { i }, L _ { j } } = 1. \\quad \\quad ( B 4 )$$\n\nProof. Consider the product\n$$\\prod _ { i = 1 } ^ { t } \\overline { \\alpha } ( L _ { i } ) = \\prod _ { e \\in E } \\prod _ { v \\in e } \\overline { \\alpha } ( v ).$$\nAfter swapping pairs of adjacent operators whenever necessary (which corresponds to performing the bubble sort with respect to the order â‰º on the list L ), we can rewrite this product in the form ( -1) s âˆ v âˆˆ V Î± v ( ) deg v ( ) , where s = âˆ‘ 1 â‰¤ i&lt;j â‰¤ t, L i glyph[follows] L j M L ,L i j . Since each operator squares to I , the product simplifies to ( -1) s I and the result folglyph[square]\nlows.\n\nThus, if M is a valid Gram matrix for H , then it is easy to check whether or not there exists a Pauli-based proof satisfying (i) and (ii) respecting M or not. If it does exist, then we call this Gram matrix magic .\n$$U _ { \\mathbf A } = \\begin{pmatrix} \\mathbf A / \\mu &. \\\\. &. \\end{pmatrix}$$\nThis framework, introduced in [28, 29], represents any sub-normalized matrix as the top-left block of a unitary U A . This definition generalizes to any matrix A âˆˆ R m n Ã— by building the block-encoding of its symmetrized version A âˆˆ R ( m n + ) Ã— ( m n + ) such that:\n$$\\overline { \\mathbf A } = \\begin{pmatrix} 0 & \\mathbf A \\\\ \\mathbf A ^ { \\dagger } & 0 \\end{pmatrix}$$\nThe property of constructing a block-encoding of a matrix A = [ a ij ] i,j âˆˆ R m n Ã— can be reduced to being able to perform certain mappings regarding the rows of the matrix A ( p ) and the columns of the matrix A (1 -p ) for some p âˆˆ [0 , 1] where A ( k ) denotes the matrix with elements ( a ij ) k âˆˆ C . If we define s q ( A ) = max i âˆˆ [ m ] â€– a i â€– q q to be the maximum /lscript q -norm over the rows a i of A , then we have the following result:\nLemma 2.1 (Constructing block-encodings [28, 29]) . Let p âˆˆ [0 , 1] and Î±, Î² âˆˆ R + . Let A âˆˆ R m n Ã— be a matrix with s 2 p ( A ) â‰¤ Î± 2 and s 2(1 -p ) ( A /latticetop ) â‰¤ Î² 2 . We can implement an Î±Î² -block-encoding of A by applying a constant number of times the unitaries O r and O c such that:\nThe last thing that we need to do before using the integration formula is to express ã€ˆ | i WR VR j âˆ— | â€² 2 ã€‰ in terms of the coordinates of W . To do this, first define Q = R V R âˆ— so that\n$$R ^ { * } V R \\left | j _ { 2 } ^ { \\prime } \\right \\rangle = Q \\left | j _ { 2 } ^ { \\prime } \\right \\rangle \\\\ = \\sum _ { \\alpha } Q _ { \\alpha, j _ { 2 } ^ { \\prime } } \\left | \\alpha \\right \\rangle,$$\n\nand thus\n$$\\overline { \\langle i | W R ^ { * } V R \\left | j _ { 2 } ^ { \\prime } \\rangle } = \\overline { \\langle i \\right | W Q \\left | j _ { 2 } ^ { \\prime } \\rangle } \\\\ = \\sum _ { \\alpha } \\overline { Q _ { \\alpha, j _ { 2 } ^ { \\prime } } } \\, \\overline { \\langle i | W \\left | \\alpha \\rangle }.$$\nSubstituting this expression back into the integral we see that\n$$& \\int \\int W _ { i, j _ { 1 } } W _ { i, j _ { 2 } } \\overline { W _ { i, j _ { 1 } ^ { \\prime } } } \\, \\overline { \\langle i | W R ^ { * } V R } \\, | j _ { 2 } ^ { \\prime } \\rangle d W \\rho _ { 2 } ( R ) d R \\\\ & = \\sum _ { \\alpha } \\int \\overline { Q _ { \\alpha, j _ { 2 } ^ { \\prime } } } \\int W _ { i, j _ { 1 } } W _ { i, j _ { 2 } } \\overline { W _ { i, j _ { 1 } ^ { \\prime } } } \\, \\overline { \\langle i | W \\, | \\alpha \\rangle } d W \\rho _ { 2 } ( R ) d R \\\\ & = \\sum _ { \\alpha } \\int \\overline { Q _ { \\alpha, j _ { 2 } ^ { \\prime } } } \\int W _ { i, j _ { 1 } } W _ { i, j _ { 2 } } \\overline { W _ { i, j _ { 1 } ^ { \\prime } } } \\, \\overline { W _ { i, \\alpha } } d W \\rho _ { 2 } ( R ) d R.$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] A_Variational_Quantum_Algorithm_For_Approximating_Convex_Roofs - https://arxiv.org/abs/2203.02099\n[2] Irreducible_magic_sets_for_$n$-qubit_systems - https://arxiv.org/abs/2202.13141\n[3] Quantum_Reinforcement_Learning_via_Policy_Iteration - https://arxiv.org/abs/2203.01889\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç çš„çº é”™é˜ˆå€¼ï¼ˆ~1% é”™è¯¯ç‡ï¼‰å¦‚ä½•æ¨å¯¼ï¼Ÿå®éªŒä¸­å¦‚ä½•é€¼è¿‘è¿™ä¸€ç†è®ºæé™ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç çš„ Syndrome æµ‹é‡ï¼ˆé”™è¯¯æ£€æµ‹ï¼‰å¦‚ä½•é€šè¿‡è¾…åŠ©é‡å­æ¯”ç‰¹å®ç°ï¼Ÿå…¶ç”µè·¯è®¾è®¡çš„å…³é”®æŒ‘æˆ˜æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç å¦‚ä½•åŒºåˆ†ä½ç¿»è½¬ï¼ˆX é”™è¯¯ï¼‰å’Œç›¸ä½ç¿»è½¬ï¼ˆZ é”™è¯¯ï¼‰ï¼Ÿçº é”™æµç¨‹æ˜¯å¦éœ€è¦é’ˆå¯¹ä¸åŒé”™è¯¯ç±»å‹åˆ†åˆ«å¤„ç†ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­é”™è¯¯çš„æ—¶ç©ºç›¸å…³æ€§ï¼ˆå¦‚è¿ç»­é”™è¯¯è„‰å†²ï¼‰æ˜¯å¦ä¼šå½±å“è¡¨é¢ç çš„çº é”™æ•ˆç‡ï¼Ÿå¦‚ä½•é€šè¿‡ç¼–ç è®¾è®¡ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç çš„ä¿®è¡¥ï¼ˆpatchingï¼‰æŠ€æœ¯å¦‚ä½•å®ç°å¯¹å±€éƒ¨é”™è¯¯çš„é«˜æ•ˆçº æ­£ï¼Ÿå…¶ä¸ä¼ ç»Ÿé‡å­çº é”™ç çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nSteps (b) to (c) of our algorithm provide an efficient algorithm to check whether or not a hypergraph admits a Pauli-based magic assignment satisfying (i) and (ii). Therefore, in a sense, they answer question (3). Additionally, step (c) allows us to generate and iterate through magic assignments of minimal structures. The main result we exploit is the following theorem.\nTheorem 1 Let H be a proper Eulerian hypergraph with valid Gram space V . Let B be any basis for V . Then,\nFIG. 3. The fourth magic set with vertex-transitive graph of compatibility that cannot be reduced to the square or pentagram that we have found, MS3-27, requires n = 3 qubits and has 27 observables and 27 contexts. It does not admit a straight line representation in the Euclidean plane. Here, observables are given by coordinate points ( x, y, z ) âˆˆ Z 3 3 (the x axis is horizontal, the y axis goes into the page, and the z axis is vertical) and all contexts can be obtained by applying translations to a starter context. A possible starter context Î² given by the observables corresponding to the coordinates (0 , 0 0) (1 0 0) (0 1 0) (0 0 1) is depicted by the , , , , , , , , , , four larger dots. All 27 contexts can be generated by applying the translations T a,b,c : Z 3 3 â†’ Z 3 3 , 0 â‰¤ a, b, c â‰¤ 2 given by ( x, y, z ) â†’ ( x + a, y + b, z + ) to each of the observables c of the starter context. For example, one obtains the context { ZY Y, XXY,ZXZ,XY Z } by applying the translation T 1 2 0 , , to the observables of Î² . In the example shown, all the contexts are negative. The dotted edges appear only as a visual aid to make clear the correspondence of the vertices to the coordinates. Like the magic square, see Fig. 1(a), MS3-27 can be implemented using all 3 n n -qubit Pauli observables not containing I .\n![Image](https://serverip/images/Irreducible_magic_sets_for_%24n%24-qubit_systems-with-image-refs_artifacts/image_000005_4562035722b7260495c48f26ea68d76546fb8908a95d17c996836097143ddd8f.png)\n- 1. H has a magic assignment with Pauli observables if and only if there is a magic Gram matrix in B .\n- 2. H has a magic assignment with Pauli observables for a system of k qubits satisfying (i) and (ii) if and only if there is a magic Gram matrix of binary rank at most 2 k in V .\n- (1) Delete each vertex in /u1D451 ( x , /u1D462 /u1D45B î‰€ ) and each edge that is incident with at least one vertex in /u1D451 ( x , /u1D462 /u1D45B î‰€ ) in îˆº . Let îˆº 1 be the resulting graph.\n- (2) For each ordered pair ( /u1D462 /u1D44E , /u1D462 /u1D44F ) of vertices in /u1D449 ( î‰€ ) such that ( /u1D462 /u1D44E , /u1D462 /u1D44F ) âˆ‰ /u1D438 ( î‰€ ) , delete each edge from a vertex in /u1D451 ( x , /u1D462 /u1D44E ) to a vertex in /u1D451 ( x , /u1D462 /u1D44F ) in îˆº 1 . Let îˆº 2 be the resulting graph.\nRecall that, by Lemma 3, | /u1D451 ( x , /u1D462 0 ) | = 1 , where /u1D462 0 is the root of î‰€ and, by Lemma 12, for each leaf /u1D462 /u1D456 of î‰€ , /u1D451 ( x , /u1D462 /u1D456 ) contains the leaf of îˆº that has the same label as /u1D462 /u1D456 . We next obtain a graph îˆº 3 from îˆº 2 such that îˆº 3 is a subdivision of î‰€ . For each /u1D462 /u1D459 âˆˆ /u1D449 ( î‰€ ) /uni29F5 { /u1D462 0 } , it follows from Lemma 13, that /u1D451 ( x , /u1D462 /u1D459 ) is a directed path of îˆº and therefore, by construction, also of îˆº 2 . Let /u1D462 /u1D456 be the unique ancestor of /u1D462 /u1D459 in î‰€ . Let /u1D45D = /u1D45D 1 , /u1D45D 2 , â€¦ , /u1D45D /u1D458 be the directed path of îˆº that is induced by /u1D451 ( x , /u1D462 /u1D456 ) and, similarly, let /u1D45D â€² = /u1D45D â€² 1 , /u1D45D â€² 2 , â€¦ , /u1D45D â€² /u1D458 â€² be the directed path of îˆº that is induced by /u1D451 ( x , /u1D462 /u1D459 ) . By Lemma 14 and Corollary 15, there exists exactly one edge /u1D452 in îˆº that joins a vertex of /u1D45D to a vertex of /u1D45D â€² and, in particular, /u1D452 is directed out of /u1D45D /u1D458 . Hence /u1D452 = ( /u1D45D /u1D458 , /u1D45D â€² /u1D457 ) for some 1 â‰¤ /u1D457 â‰¤ /u1D458 â€² . As /u1D462 /u1D456 is the unique parent of /u1D462 /u1D459 in î‰€ , any edge in îˆº that is directed into a vertex in { /u1D45D â€² 1 , /u1D45D â€² 2 , /u1D45D â€² /u1D457 -1 , /u1D45D â€² /u1D457 +1 , â€¦ , /u1D45D â€² /u1D458 â€² } and does not lie on /u1D45D â€² has been deleted in Step\n(2) above. Moreover, again by Lemma 14 and Corollary 15, any edge in îˆº that joins a vertex in /u1D451 ( x , /u1D462 /u1D459 ) with a vertex in /u1D451 ( x , /u1D462 /u1D459 â€² ) , where /u1D462 /u1D459 â€² is a child of /u1D462 /u1D459 in î‰€ , is directed out of /u1D45D â€² /u1D458 â€² . Hence, any edge in îˆº that is directed out of a vertex in { /u1D45D â€² 1 , /u1D45D â€² 2 , â€¦ , /u1D45D â€² /u1D458 â€² -1 } and does not lie on /u1D45D â€² has also been deleted in Step (2) above. For the upcoming construction step, we call { /u1D45D â€² 1 , /u1D45D â€² 2 , â€¦ , /u1D45D â€² /u1D457 -1 } the set of dangling vertices in îˆº 2 with respect to /u1D462 /u1D459 . This set may or may not be empty. Now obtain a graph îˆº 3 from îˆº 2 by deleting the set of dangling vertices in îˆº 2 for each vertex /u1D462 /u1D459 âˆˆ /u1D449 ( î‰€ )âˆ–{ /u1D462 0 } . It is straightforward to check that îˆº 3 is a subdivision of î‰€ and that î‰€ can be obtained from this subdivision by suppressing each vertex with in-degree 1 and out-degree 1 in îˆº 3 . Thus, if /u1D43B ( x ) = 0 , then îˆº displays î‰€ .\nWe complete the proof by showing that /u1D443 /u1D43C ( x ) = 0 for each 1 â‰¤ /u1D43C â‰¤ 12 .\n- ( /uni27F8 ) Suppose that îˆº displays î‰€ . Then there exists a subset /u1D449 of /u1D449 ( îˆº ) and a subset /u1D438 of /u1D438 ( îˆº ) such that î‰€ can be obtained from îˆº by deleting each vertex in /u1D449 and each edge in /u1D438 from îˆº and, subsequently, suppressing any resulting vertex of in-degree 1 and out-degree 1. Without loss of generality, we choose /u1D449 such that its size | /u1D449 | is maximized. Let { /u1D462 0 , /u1D462 1 , â€¦ , /u1D462 /u1D45B î‰€ -1 } be the vertices of î‰€ , and let { /u1D463 0 , /u1D463 1 , â€¦ , /u1D463 /u1D45B îˆº -1 } be the vertices of îˆº . Furthermore, let î‰€ â€² be the graph obtained from îˆº by deleting each vertex in /u1D449 and each edge in /u1D438 from îˆº . By construction, î‰€ â€² is a subdivision of î‰€ . Consider the map /u1D45A âˆ¶ /u1D449 ( î‰€ ) â†’ 2 /u1D449 ( î‰€ â€² ) that maps each /u1D462 /u1D456 âˆˆ /u1D449 ( î‰€ ) to a subset of /u1D449 ( î‰€ â€² ) such that /u1D45A ( /u1D462 /u1D456 ) contains precisely each vertex /u1D463 /u1D457 of î‰€ â€² with /u1D436 î‰€ â€² ( /u1D463 /u1D457 ) = /u1D436 î‰€ ( /u1D462 /u1D456 ) . Now we define x âˆˆ /u1D539 /u1D45A . For each /u1D465 /u1D456,/u1D457 with 0 â‰¤ /u1D456 â‰¤ /u1D45B î‰€ - 1 and 0 â‰¤ /u1D457 â‰¤ /u1D45B îˆº - 1 , we set /u1D465 /u1D456,/u1D457 = 1 if /u1D463 /u1D457 âˆˆ /u1D45A ( /u1D462 /u1D456 ) and, /u1D465 /u1D456,/u1D457 = 0 otherwise. Moreover, for each 0 â‰¤ /u1D457 â‰¤ /u1D45B îˆº - 1 , we set /u1D465 /u1D45B î‰€ ,/u1D457 = 1 if /u1D463 /u1D457 âˆˆ /u1D449 and /u1D465 /u1D45B î‰€ ,/u1D457 = 0 otherwise. Lastly, to keep with the notation introduced in Section 4.1, let /u1D451 ( x , /u1D462 /u1D456 ) = /u1D45A ( /u1D462 /u1D456 ) for each /u1D456 with 0 â‰¤ /u1D456 â‰¤ /u1D45B î‰€ - 1 , and let /u1D451 ( x , /u1D462 /u1D45B î‰€ ) = /u1D449 .\n- (1) As î‰€ â€² is a subdivision of î‰€ , the root of î‰€ â€² is the only vertex of î‰€ â€² whose set of leaf descendants is /u1D44B and, so /u1D451 ( x , /u1D462 0 ) = 1 . Furthermore, by construction, /u1D451 ( x , /u1D462 /u1D456 ) &gt; 0 for each /u1D462 /u1D456 âˆˆ /u1D449 ( î‰€ ) . By Lemma 3, /u1D443 1 ( x ) = 0 follows.\n- | | | | (2) For each vertex /u1D463 /u1D457 âˆˆ /u1D449 ( î‰€ â€² ) there exists exactly one vertex /u1D462 /u1D456 âˆˆ /u1D449 ( î‰€ ) such that /u1D436 î‰€ â€² ( /u1D463 /u1D457 ) = /u1D436 î‰€ ( /u1D462 /u1D456 ) . Moreover /u1D451 ( x , /u1D462 /u1D45B î‰€ ) = /u1D449 . Hence /u1D443 2 ( x ) = 0 follows from Lemma 4.\n- (3) Set /u1D467 /u1D456,/u1D457 = /u1D465 /u1D456,/u1D457 1 /u1D465 /u1D456,/u1D457 2 , where /u1D462 /u1D456 âˆˆ /u1D449 ( î‰€ ) and /u1D463 /u1D457 âˆˆ /u1D449 ( îˆº ) is tree vertex. By Lemma 5, this implies that /u1D443 3 ( x ) = 0 . Similarly, set /u1D467 /u1D456,/u1D457 = /u1D465 /u1D456,/u1D457 1 /u1D465 /u1D456,/u1D457 2 , where /u1D462 /u1D456 âˆˆ /u1D449 ( î‰€ ) and /u1D463 /u1D457 âˆˆ /u1D449 ( îˆº ) is reticulation vertex. Then, by Lemma 7, we have /u1D443 5 ( x ) = 0 . Lastly, set Ì‚ /u1D467 /u1D456, 2 /u1D457 = /u1D465 /u1D456,/u1D457 /u1D465 /u1D456,/u1D457 1 and Ì‚ /u1D467 /u1D456, 2 +1 /u1D457 = /u1D465 /u1D456,/u1D457 /u1D465 /u1D456,/u1D457 2 , where /u1D462 /u1D456 âˆˆ /u1D449 ( î‰€ ) and /u1D463 /u1D457 âˆˆ /u1D449 ( îˆº ) is a tree vertex. It then follows by Lemma 10 that /u1D443 8 ( x ) = 0 .\n- (4) Since î‰€ â€² is a subdivision of î‰€ , it follows from the definition of /u1D45A (and consequently /u1D451 ) that, for each 0 â‰¤ /u1D456 â‰¤ /u1D45B î‰€ -1 , the subgraphof îˆº that is induced by the vertices in /u1D451 ( x , /u1D462 /u1D456 ) is a directed path. Now, towards a contradiction, assume that there exist a vertex /u1D462 /u1D456 in î‰€ and a vertex /u1D463 /u1D457 in îˆº such that {{ /u1D463 /u1D457 , /u1D450 1 ( /u1D463 /u1D457 ) , /u1D450 2 ( /u1D463 /u1D457 )} âŠ† /u1D451 ( x , /u1D462 /u1D456 ) . Since the subgraph of îˆº that is induced by the vertices in /u1D451 ( x , /u1D462 /u1D456 ) is a directed path, we may assume without loss of generality that there is a directed path ( /u1D450 1 ( /u1D463 /u1D457 ) = /u1D45D 1 , /u1D45D 2 , â€¦ , /u1D45D /u1D458 = /u1D450 2 ( /u1D463 /u1D457 )) in îˆº with /u1D458 â‰¥ 2 . In particular, each vertex on this path is contained in /u1D451 ( x , /u1D462 /u1D456 ) . It now follows that we can obtain a subdivision of î‰€ from îˆº by deleting all vertices in /u1D449 âˆª { /u1D45D 1 , /u1D45D 2 , â€¦ , /u1D45D /u1D458 -1 } and edges in\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Irreducible_magic_sets_for_$n$-qubit_systems - https://arxiv.org/abs/2202.13141\n[2] A_QUBO_formulation_for_the_Tree_Containment_problem - https://arxiv.org/abs/2202.11234\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¦‚ä½•é€šè¿‡æœºå™¨å­¦ä¹ ä¼˜åŒ–è¡¨é¢ç çš„é”™è¯¯æ£€æµ‹ä¸æ ¡æ­£ç­–ç•¥ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨è¶…å¯¼é‡å­èŠ¯ç‰‡ä¸­ï¼Œå¦‚ä½•å°†ç‰©ç†æ¯”ç‰¹æ’åˆ—æˆè¡¨é¢ç æ‰€éœ€çš„äºŒç»´ç½‘æ ¼ï¼Ÿè·¨å±‚è¿æ¥çš„æŠ€æœ¯ç“¶é¢ˆæ˜¯ä»€ä¹ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nä¸­æ€§åŸå­æˆ–ç¦»å­é˜±ç³»ç»Ÿä¸­ï¼Œè¡¨é¢ç çš„æ‰©å±•ï¼ˆå¦‚å¢åŠ ç è·ï¼‰å¦‚ä½•å¹³è¡¡çº é”™èƒ½åŠ›ä¸ç³»ç»Ÿå¤æ‚åº¦ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç çš„çº é”™å»¶è¿Ÿï¼ˆå³å®Œæˆä¸€è½®çº é”™æ‰€éœ€æ—¶é—´ï¼‰å¯¹é‡å­è®¡ç®—çš„å®æ—¶æ€§æœ‰ä½•å½±å“ï¼Ÿå¦‚ä½•ä¼˜åŒ–è¿™ä¸€å»¶è¿Ÿï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå®éªŒä¸­å¦‚ä½•éªŒè¯è¡¨é¢ç å¯¹é€»è¾‘é‡å­æ¯”ç‰¹çš„ä¿æŠ¤æ•ˆæœï¼Ÿæ˜¯å¦éœ€è¦é€šè¿‡é‡å­æ€å±‚ææˆåƒè¿›è¡Œç›´æ¥æµ‹é‡ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nT-carbon çš„äºŒç»´ç»“æ„æ˜¯å¦é€‚åˆæ„å»ºè¡¨é¢ç æ‰€éœ€çš„é‡å­æ¯”ç‰¹é˜µåˆ—ï¼Ÿå…¶ç”µå­ç‰¹æ€§ï¼ˆå¦‚è‡ªæ—‹ - è½¨é“è€¦åˆï¼‰å¯¹çº é”™æœ‰ä½•å½±å“ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nWe are going to use the default PauliNet architecture and change the basis set to the correlation-consistent family [60], starting from cc-pvdz to cc-pv5z. The first step is to define a Molecule object (for example named LiH ) with the geometry of LiH at an internuclear distance of 3 0141132 Bohr, and a total zero . charge and spin. Then, the PauliNet neural network can be initialized for a given basis set, say ccpvdz, from a Hartree-Fock calculation using the function from hf(LiH, basis='cc-pvdz') , meaning that the ansatz contains a single Slater determinant (cfr. Equation (33)) and uses the HF orbitals. After initialization, the network can be trained using the function train(net) , where net is the neural network object returned from the initialization procedure. This is the most expensive part of the calculation, however, the training parameters can be slightly modified to decrease the computation time, and still obtain reasonably optimized network weights (with an uncertainty of around 1 m E h ). We suggest you to use n steps = 500 , batch size = 500 and epoch size = 20 . The last step to obtain the ground state energy of LiH is to call the function evaluate(net) . Similarly to train(net) , evaluate(net) accepts optional parameters defining the number of Monte Carlo sweeps and the length of the Markov chain sampled at each step. For these two, we suggest the following values, n steps = 400 and sample size\n= 800 . Save the obtained energy and the estimated error, and repeat the same process for the other basis sets. The choice of training parameters was such that the optimization does not take too long time. If you want to investigate the effects of the training procedure on the final energy and uncertainty, as an advanced exercise you can modify the values of n steps and batch size in the train(net) function (hint: modify one value at a time to understand their role).\n## 3.2.2 CCSD(T) calculations\nIn this part we are going to perform CCSD(T) calculations in combination with the four basis sets used above. You can use PySCF for performing these calculations, and they should take significantly less time than the PauliNet ones. PySCF has a pretty extensive user guide available online at https://pyscf.org/, with many examples. We suggest you to have a look at it if you get stuck at any point. The first step is again to define the lithium hydride molecule, this time in a data-structure that PySCF understands. This can be done with the function gto.M(...) , which accepts a number of arguments similar to the construction of the Molecule object for the DeepQMC package. Then, you can create a restricted HF instance with rhf = scf.RHF(mol) , where mol is the molecule you just created (hint: make sure to set the correct basis set with mol.basis = 'cc-pvdz' and build it with mol.build() ). The rhf object can be used to create the coupled cluster instance with cc = cc.CCSD(rhf) . The energy for each method can then be obtained by calling .kernel() on the HF and coupled cluster objects, and .ccsd t() for the perturbative triples correction. Save all these energies and repeat the process for all basis sets. If you have a powerful computer, as an additional exercise you can try to compute the full CI energy, however, you will probably be able to get it at most with the triple zeta basis set (hint: for such a small molecule, the CCSD(T) and FCI energies are very similar).\n## 3.2.3 Comparison of PauliNet and CCSD(T)\n- [21] T. Skovhus, T. Olsen, Dynamic transverse magnetic susceptibility in the projector augmented-wave method: Application to Fe, Ni, and Co, Phys. Rev. B 103 (2021) 245110.\n- [22] F. Aryasetiawan, K. Karlsson, Phys. Rev. B 60 (1999) 7419.\n- [23] K. Karlsson, F. Aryasetiawan, Phys. Rev. B 62 (2000) 3006.\n- [24] T. Kotani, M. van Schilfgaarde, J. Phys.: Condens. Matter 20 (2008) 295214.\n- [25] S Â¸ aÂ¸ioË˜lu, s g A. Schindlmayr, C. Friedrich, F. Freimuth, S.BlÂ¨gel, Phys. Rev. B 81 (2010) 054434. u\n- [26] M. MÂ¨ uller, C. Friedrich, S. BlÂ¨gel, Phys. Rev. B 94 (2016) 064433. u\n- [27] E. Runge, E. Gross, Phys. Rev. Lett. 52 (1984) 997.\n- [28] M. A. L. Marques, N. T. Maitra, F. M. S. Nogueira, E. K. U. Gross, A. Rubio (Eds.), Fundamentals of Time-Dependent Density Functional Theory, Vol. 837, Lecture Notes in Physics, Springer-Verlag, Berlin Heidelberg, 2012.\n- [29] S. Baroni, R. Gebauer, The Liouville-Lanczos Approach to Time-Dependent Density-Functional (Perturbation) Theory, Ref. [28], chapter 19, p. 375-390.\n- [30] D. Rocca, R. Gebauer, Y. Saad, S. Baroni, J. Chem. Phys. 128 (2008) 154105.\n- [31] I. Timrov, N. Vast, R. Gebauer, S. Baroni, Phys. Rev. B 88 (2013) 064301, ibid. 91 , 139901 (2015).\n- [32] S. Baroni, P. Giannozzi, A. Testa, Green's-function approach to linear response in solids, Phys. Rev. Lett. 58 (1987) 1861.\n- [33] S. Baroni, S. de Gironcoli, A. D. Corso, P. Giannozzi, Phonons and related crystal properties from densityfunctional perturbation theory, Rev. Mod. Phys. 73 (2) (2001) 515.\n- [34] O. MalcioiË˜lu, R. Gebauer, D. Rocca, S. Baroni, Comput. Phys. Commun. 182 (2011) 1744. g\n- [35] X. Ge, S. J. Binnie, D. Rocca, R. Gebauer, S. Baroni, turboTDDFT 2.0 - Hybrid functionals and new algorithms within time-dependent density-functional perturbation theory, Comput. Phys. Commun. 185 (2014) 2080.\n- [36] I. Timrov, N. Vast, R. Gebauer, S. Baroni, Comput. Phys. Commun. 196 (2015) 460.\n- [37] I. Timrov, M. Markov, T. Gorni, M. Raynaud, O. Motornyi, R. Gebauer, S. Baroni, N. Vast, Phys. Rev. B 95 (2017) 094301.\n- [38] O. Motornyi, N. Vast, I. Timrov, O. Baseggio, S. Baroni, A. Dal Corso, Phys. Rev. B 102 (2020) 035156.\n- [39] The GNU General Public License: http://www.gnu.org/licenses/gpl.html .\n- [40] P. Giannozzi, S. Baroni, N. Bonini, M. Calandra, R. Car, C. Cavazzoni, D. Ceresoli, G. Chiarotti, M. Cococcioni, I. Dabo, A. Dal Corso, S. De Gironcoli, S. Fabris, G. Fratesi, R. Gebauer, U. Gerstmann, C. Gougoussis, A. Kokalj, M. Lazzeri, L. Martin-Samos, N. Marzari, F. Mauri, R. Mazzarello, S. Paolini, A. Pasquarello, L. Paulatto, C. Sbraccia, S. Scandolo, G. Sclauzero, A. Seitsonen, A. Smogunov, P. Umari, R. Wentzcovitch, Quantum ESPRESSO: A modular and open-source software project for quantum simulations of materials, J. Phys.: Condens. Matter 21 (2009) 395502.\n- [41] P. Giannozzi, O. Andreussi, T. Brumme, O. Bunau, M. Buongiorno Nardelli, M. Calandra, R. Car, C. Cavazzoni, D. Ceresoli, M. Cococcioni, N. Colonna, I. Carnimeo, A. Dal Corso, S. de Gironcoli, P. Delugas, R. A. DiStasio Jr., A. Ferretti, A. Floris, G. Fratesi, G. Fugallo, R. Gebauer, U. Gerstmann, F. Giustino, T. Gorni, J. Jia, M. Kawamura, H.-Y. Ko, A. Kokalj, E. KÂ¨Â¸ cÂ¨kbenli, M. Lazzeri, M. Marsili, N. Marzari, F. Mauri, u u N. L. Nguyen, H.-V. Nguyen, A. Otero-de-la Rosa, L. Paulatto, S. PoncÂ´, D. Rocca, R. Sabatini, B. Santra, e M. Schlipf, A. Seitsonen, A. Smogunov, I. Timrov, T. Thonhauser, P. Umari, N. Vast, S. Baroni, Advanced capabilities for materials modelling with Quantum ESPRESSO, J. Phys.: Condens. Matter 29 (2017) 465901.\n- [42] P. Giannozzi, O. Baseggio, P. Bonf` a, D. Brunato, R. Car, I. Carnimeo, C. Cavazzoni, S. de Gironcoli, P. Delugas, F. Ferrari Ruffino, A. Ferretti, N. Marzari, I. Timrov, A. Urru, S. Baroni, Quantum ESPRESSO toward the exascale, J. Chem. Phys. 152 (2020) 154105.\n- [43] O. Halpern, M. Johnson, On the Magnetic Scattering of Neutrons, Phys. Rev. 55 (1939) 898.\n- [44] M. Blume, Polarization Effects in the Magnetic Elastic Scattering of Slow Neutrons, Phys. Rev. 130 (1963) 1670.\n- [45] W. Jones, N. H. March, Theoretical solid state physics, Volume 1, Courier Corporation, 1985.\n- [46] T. Gorni, I. Timrov, S. Baroni, Spin dynamics from time-dependent density functional perturbation theory, Eur. Phys. J. B 91 (2018) 249.\n- [47] T. Gorni, Spin-fluctuation spectra in magnetic systems: a novel approach based on tddft, Ph.D. thesis, Scuola Internazionale Superiore di Studi Avanzati (SISSA), Trieste, Italy (2016, http://hdl.handle.net/20.500. 11767/43342 ).\n- [48] We use a hat ' Ë† ' on top of letters to indicate operators (e.g. Ë† ), while these same operators in the coordinate V representation are written without the hat and with the explicit dependence on the position vector r [e.g. V ( r )]. Moreover, we use a tilde ' Ëœ ' to indicate a Fourier transform of various quantities from the time domain [e.g. V ( )] t to the frequency domain [e.g. Ëœ ( V Ï‰ )]. A combination of these two notations is often used in this work.\n- [49] With the upper case letter we denote a 2 Ã— 2 matrix potential, while with the lower case letter we denote scalar potentials.\n- [50] L. Kleinman, Phys. Rev. B 21 (1980) 2630.\n- [51] G. Bachelet, SchlÂ¨ter, Phys. Rev. B 25 (1982) 2103. u\n- [52] G. Bachelet, D. Hamann, SchlÂ¨ter, Phys. Rev. B 26 (1982) 4199. u\n- [53] L. Hemstreet, C. Fong, J. Nelson, Phys. Rev. B 47 (1993) 4238.\n- [54] D. Ceresoli, U. Gerstmann, A. Seitsonen, F. Mauri, Phys. Rev. B 81 (2010) 060409(R).\n- [55] N. Ashcroft, N. Mermin, Solid State Physics, Saunders College Publishing, Philadelphia, 1976.\n- [56] A. Dal Corso, Phys. Rev. B 82 (2010) 075116.\n- [57] We note that in the second term of Eq. (9) we symbolically mean a scalar product, while in the second term of Eq. (10) we symbolically mean a matrix-vector multiplication.\n- [58] These relations are a consequence of the fact that chargeand magnetization-density responses are real functions in space and time.\n- [59] N. Singh, P. Elliott, T. Nautiyal, J. K. Dewhurst, S. Sharma, Phys. Rev. B 99 (2019) 035151.\n- [60] S. Lehtola, M. Marques, Many recent density functionals are numerically unstable, arXiv:2206.14062 (2022).\n- [61] J. Sun, A. Ruzsinszky, J. Perdew, Phys. Rev. Lett. 115 (2015) 036402.\n- [62] M. Ekholm, D. Gambino, H. JÂ¨ onsson, F. TasnÂ´di, B. Alling, I. Abrikosov, Assessing the SCAN functional a for itinerant electron ferromagnets, Phys. Rev. B 98 (2018) 094413.\n- [63] F. Tran, G. Baudesson, J. Carrete, G. Madsen, P. Blaha, K. Schwarz, D. Singh, Shortcomings of meta-GGA functionals when describing magnetism, Phys. Rev. B 102 (2020) 024407.\n- [64] T. Skovhus, T. Olsen, H. Ronnow, arXiv:2110.07282 (2022).\n- [65] T. Skovhus, T. Olsen, arXiv:2203.04796 (2022).\n- [66] M. Gokhale, A. Ormeci, D. Mills, Phys. Rev. B 46 (1992) 8978.\n- [67] Y. Saad, Iterative Methods for Sparse Linear Systems, 2nd Edition, SIAM, Philadelphia, 2003.\n- [68] M. GrÂ¨ uning, A. Marini, X. Gonze, Comput. Math. Sci. 50 (2011) 2148.\n- [69] A. Mostafazadeh, Pseudo-Hermiticity versus PT symmetry: The necessary condition for the reality of the spectrum of a non-Hermitian Hamiltonian, J. Math. Phys. 43 (2002) 205.\n- [70] GNU Autoconf: https://www.gnu.org/software/autoconf .\n- [71] CMake is an open-source, cross-platform family of tools designed to build, test and package software: https: //cmake.org/ .\n- [72] Message passing interface forum, Int. J. Supercomput. Appl. 8 (1994) 159.\n- [73] http://theossrv1.epfl.ch/Main/Pseudopotentials .\n- [74] D. Soriano, M. I. Katsnelson, J. FernÂ´ndez-Rossier, Magnetic two-dimensional chromium trihalides: A theoa retical perspective, Nano Letters 20 (9) (2020) 6225-6234.\n- [75] T. Gorni, O. Baseggio, P. Delugas, S. Baroni, I. Timrov, turboMagnon - A code for the simulation of spin-wave spectra using the Liouville-Lanczos approach to time-dependent density-functional perturbation theory, Materials Cloud Archive 2022.89 (2022), doi: 10.24435/materialscloud:6j-kd. doi:10.24435/materialscloud: 6j-kd .\n- URL https://archive.materialscloud.org/record/2022.89\n- [76] J. Goldstone, A. Salam, S. Weinberg, Broken symmetries, Phys. Rev. 127 (1962) 965-970.\n- [77] H. Watanabe, H. Murayama, Unified description of nambu-goldstone bosons without lorentz invariance, Phys. Rev. Lett. 108 (2012) 251602.\n- [78] P. Delugas, O. Baseggio, I. Timrov, S. Baroni, T. Gorni, Magnon-phonon interactions open a gap at the Dirac point in the spin-wave spectra of CrI 3 2D magnets, submitted (arXiv:2203.01120) (2021).\n- [79] L. Chen, J.-H. Chung, B. Gao, T. Chen, M. B. Stone, A. I. Kolesnikov, Q. Huang, P. Dai, Topological spin excitations in honeycomb ferromagnet CrI , Phys. Rev. X 8 (4) (2018) 041028. 3\n- [80] L. Chen, J.-H. Chung, T. Chen, C. Duan, A. Schneidewind, I. Radelytskyi, D. J. Voneshen, R. A. Ewings, M. B. Stone, A. I. Kolesnikov, B. Winn, S. Chi, R. A. Mole, D. H. Yu, B. Gao, P. Dai, Magnetic anisotropy in ferromagnetic CrI 3 , Phys. Rev. B 101 (2020) 134418.\n- [81] L. Del Re, A. Toschi, Dynamical vertex approximation for many-electron systems with spontaneously broken su(2) symmetry, Phys. Rev. B 104 (2021) 085120.\n- [82] G. Giuliani, G. Vignale, Quantum theory of the electron liquid, Cambridge university press, 2005.\n- [83] Description of the 'Galileo100' HPC cluster at CINECA: https://www.hpc.cineca.it/hardware/ galileo100 .\n- [84] H. Monkhorst, J. Pack, Special points for Brillouin-zone integrations, Phys. Rev. B 13 (1976) 5188.\n- [85] The latest development version of the Quantum ESPRESSO distribution can be downloaded from https: //gitlab.com/QEF/q-e .\n- [86] The official release of the Quantum ESPRESSO distribution can be downloaded from https://www. quantum-espresso.org .\n## Molecular property prediction with photonic chip-based machine learning\nHui Zhang, 1, âˆ— Jonathan Wei Zhong Lau, 2, âˆ— Lingxiao Wan, 3 Liang Shi, 4 Yuzhi Shi, 5 Hong Cai, 6 Xianshu Luo, 7 Guo-Qiang Lo, 7 Chee-Kong Lee, 8, â€  Leong Chuan Kwek, 3,9,10,11, â€  and Ai Qun Liu 3, â€ \nIn P. Smolensky (1990), the author suggests using a representation based on tensor product :   Tensor   Product   Representation   (TPR),   to   capture   syntactic bindings across sentences. [49, 50] Tensor product is here understood as the Kronecker product, denoted by . Given two matrices A, B we define A B to be âŠ— âŠ— the block matrix where every element of A is multiplied by B (Fig. 2.1). TPR is a structure where every unit of a sentence can be part of the representation of every constituent. It can be compositionally encoded from the numerical vectors representing the composing words, and hence offers the ideal framework to build-up a structure to embed not only words, but also sentences.\n$$\\begin{array} { c c c } a _ { 1 1 } B & \\cdots & a _ { 1 n } B \\\\ \\vdots & \\ddots & \\vdots \\\\ a _ { m 1 } B & \\cdots & a _ { m n } B \\end{array}$$\nBased on Lambek's pregroup algebra, in Mehrnoosh et al. (2010), the authors introduce the CSC algorithm, which develops another implementation of tensor based representation of the meaning of a sentence. [34] This algorithm can be implemented on a quantum computer. Let the linear map Î£âŸ¨ ii| (Fig. 2.2), which is the sum over all the basis vectors of the space N. We call this linear map a cap . It formally describes the state of log  EPR pairs (a generalization of n quantum entanglement). If the basis is of size n and is orthonormal, the cap can simply be thought of as a row vector of size n 2 , filled of 0, and valued 1 at the positions  ii|. The steps of the CSC algorithm are detailed in Fig. 2.3. âŸ¨\n$$\\sum _ { i } \\langle i | \\colon =$$\n\nFig. 2.2 (Zeng &amp; Coecke, 2016) : Definition of a cap\n- 1 Compute the tensor product words Wo wk in the order that each word appears in the sentence\n- 2 Construct a linear map that represents the grammatical type reduction by the vectors with the appropriate caps. For example, given that the pregroup type reduction of a nounhransitive verblnoun sentence is:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] A_photonic_chip-based_machine_learning_approach_for_the_prediction_of_molecular_properties - https://arxiv.org/abs/2203.02285\n[2] A_gentle_introduction_to_Quantum_Natural_Language_Processing - https://arxiv.org/abs/2202.11766\n[3] turboMagnon_--_A_code_for_the_simulation_of_spin-wave_spectra_using_the_Liouville-Lanczos_approach_to_time-dependent_density-functional_perturbation_theory - https://arxiv.org/abs/2203.01120\n[4] Machine_Learning_Wavefunction - https://arxiv.org/abs/2202.13916\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nç¡¼æºæ‚é‡‘åˆšçŸ³çš„ç¼ºé™·ï¼ˆå¦‚è‰²å¿ƒï¼‰åœ¨è¡¨é¢ç ä¸­èƒ½å¦ä½œä¸ºé‡å­æ¯”ç‰¹æˆ–è¾…åŠ©æ¢æµ‹å™¨ï¼Ÿå¦‚ä½•é™ä½ç¼ºé™·é—´çš„ä¸²æ‰°ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\näºŒç»´èŒƒå¾·åå¼‚è´¨ç»“ï¼ˆå¦‚çŸ³å¢¨çƒ¯ / æ°®åŒ–ç¡¼ï¼‰æ˜¯å¦å¯ç”¨äºè¡¨é¢ç çš„é›†æˆåŒ–è®¾è®¡ï¼Ÿå…¶ç•Œé¢è´¨é‡å¯¹ç›¸å¹²æ€§çš„å½±å“å¦‚ä½•ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç ä¸å…¶ä»–é‡å­çº é”™ç ï¼ˆå¦‚ Steane ç ã€CSS ç ï¼‰ç›¸æ¯”ï¼Œåœ¨èµ„æºå¼€é”€å’Œå®¹é”™èƒ½åŠ›ä¸Šæœ‰ä½•ä¼˜åŠ¿ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nIn quantum image processing, we have used different image encoding methods for edge detection and binary image classification. When compared to classical process, quantum provides advantage in runtime, space complexity i.e. number of bits/qubits required for image encoding, but is not sufficient in terms of depth and width of image. With Quantum methods it is quite challenging to handle larger images as circuit design gets complex with increased number of qubits required, leading to addition of noise with inaccurate edge detection and classification results. In this project, we have used gate based quantum statevector and qasm simulator that are slower in performance which in-turn increases the training time for larger datasets and requires splitting of data into smaller sets and recombining to get higher accuracy for larger image pixel and datasets. While running real quantum may provides better performance but it is more exposed to the noise from the devices. As advancements with this projects, our team is working to analyse impact of different noise models on the quantum image encoding circuit and its results when processing smaller pixel as well as large pixel images. Our work in future will include implementing from quantum processed results for image verification with original/real-time images to reach better accuracy.\n## REFERENCES\n- [1] Yue Ruan, Xiling Xue, and Yuanxia Shen. Quantum image processing: Opportunities and challenges. Mathematical Problems in Engineering , 2021, 2021.\n- [2] Fei Yan, Abdullah M Iliyasu, and Salvador E Venegas-Andraca. A survey of quantum image representations. Quantum Information Processing , 15(1):1-35, 2016.\n- [3] Salvador E Venegas-Andraca and Sougato Bose. Storing, processing, and retrieving an image using quantum mechanics. In Eric Donkor, Andrew R. Pirich, and Howard E. Brandt, editors, Quantum Information and Computation , volume 5105, pages 137 - 147. International Society for Optics and Photonics, SPIE, 2003.\n- [4] Phuc Q Le, Fangyan Dong, and Kaoru Hirota. A flexible representation of quantum images for polynomial preparation, image compression, and processing operations. Quantum Information Processing , 10(1):63-84, 2011.\n- [5] Panchi Li, Hong Xiao, and Binxu Li. Quantum representation and watermark strategy for color images based on the controlled rotation of qubits. Quantum Information Processing , 15(11):4415-4440, 2016.\n- [6] Rabia Amin Khan. An improved flexible representation of quantum images. Quantum Information Processing , 18(7):1-19, 2019.\n- [7] Yi Zhang, Kai Lu, Yinghui Gao, and Mo Wang. Neqr: a novel enhanced quantum representation of digital images. Quantum information processing , 12(8):2833-2860, 2013.\n- [8] RiGui Zhou, WenWen Hu, GaoFeng Luo, XingAo Liu, and Ping Fan. Quantum realization of the nearest neighbor value interpolation method for ineqr. Quantum Information Processing , 17(7):1-37, 2018.\n- [9] Hai-Sheng Li, Xiao Chen, Shuxiang Song, Zhixian Liao, and Jianying Fang. A block-based quantum image scrambling for gneqr. IEEE Access , 7:138233-138243, 2019.\n- [10] Simona Caraiman and Vasile Manta. Image representation and processing using ternary quantum computing. In International Conference on Adaptive and Natural Computing Algorithms , pages 366-375. Springer, 2013.\n- [11] Hai-Sheng Li, Qingxin Zhu, Ri-Gui Zhou, Lan Song, and Xing-jiang Yang. Multi-dimensional color image storage and retrieval for a normal arbitrary quantum superposition state. Quantum Information Processing , 13(4):991-1011, 2014.\n- [12] Xi-Wei Yao, Hengyan Wang, Zeyang Liao, Ming-Cheng Chen, Jian Pan, Jun Li, Kechao Zhang, Xingcheng Lin, Zhehui Wang, Zhihuang Luo, et al. Quantum image processing and its application to edge detection: theory and experiment. Physical Review X , 7(3):031041, 2017.\n- [13] VojtË‡ ech HavlÂ´ Ä±Ë‡ek, c Antonio D. CÂ´ orcoles, Kristan Temme, Aram W. Harrow, Abhinav Kandala, 'Jerry M. Chow, and Jay M. Gambetta. Supervised learning with quantum-enhanced feature spaces. Nature , 567(7747):209-212, Mar 2019.\n- [14] John Francis Canny. Finding edges and lines in images. Technical report, MASSACHUSETTS INST OF TECH CAMBRIDGE ARTIFICIAL INTELLIGENCE LAB, 1983.\n- [15] FG Irwin et al. An isotropic 3x3 image gradient operator. Presentation at Stanford AI Project , 2014(02), 1968.\n- [16] Tamar Peli and David Malah. A study of edge detection algorithms. Computer graphics and image processing , 20(1):1-21, 1982.\n- [17] John Canny. A computational approach to edge detection. IEEE Transactions on pattern analysis and machine intelligence , (6):679-698, 1986.\n- [18] Hans Peter Moravec. Obstacle avoidance and navigation in the real world by a seeing robot rover . PhD thesis, Stanford University, 1980.\n- [19] Chris Harris, Mike Stephens, et al. A combined corner and edge detector. In Alvey vision conference , volume 15, pages 10-5244. Citeseer, 1988.\n- [20] Wolfgang FÂ¨ orstner and Eberhard GÂ¨ ulch. A fast operator for detection and precise location of distinct points, corners and centres of circular features. In Proc. ISPRS intercommission conference on fast processing of photogrammetric data , pages 281-305. Interlaken, 1987.\n- [21] Stephen M Smith and J Michael Brady. Susan-a new approach to low level image processing. International journal of computer vision , 23(1):45-78, 1997.\n- [22] Minakshi Banerjee and Malay K Kundu. Handling of impreciseness in gray level corner detection using fuzzy set theoretic approach. Applied Soft Computing , 8(4):1680-1691, 2008.\n- [23] Pengao Xu, Zhenxing He, Tianhui Qiu, and Hongyang Ma. Quantum image processing algorithm using edge extraction based on kirsch operator. Optics express , 28(9):12508-12517, 2020.\n- [24] Yi Zhang, Kai Lu, and YingHui Gao. Qsobel: A novel quantum image edge extraction algorithm. Science China Information Sciences , 58, 12 2014.\n- [25] Ping Fan, Ri-Gui Zhou, Wen Wen Hu, and NaiHuan Jing. Quantum image edge extraction based on laplacian operator and zero-cross method. Quantum Information Processing , 18(1):1-23, 2019.\n- [26] Yulin Ma, Hongyang Ma, and Pengcheng Chu. Demonstration of quantum image edge extration enhancement through improved sobel operator. IEEE Access , 8:210277-210285, 2020.\n- [27] Xi-Wei Yao, Hengyan Wang, Zeyang Liao, Ming-Cheng Chen, Jian Pan, Jun Li, Kechao Zhang, Xingcheng Lin, Zhehui Wang, Zhihuang Luo, and et al. Quantum image processing and its application to edge detection: Theory and experiment. Physical Review X , 7(3), Sep 2017.\n- [28] Jae-Eun Park, Brian Quanz, Steve Wood, Heather Higgins, and Ray Harishankar. Practical application improvement to quantum svm: theory to practice. arXiv preprint arXiv:2012.07725 , 2020.\n- [29] Dawid Kopczyk. Quantum machine learning for data scientists. arXiv preprint arXiv:1804.10068 , 2018.\n- [30] Iris Cong, Soonwon Choi, and Mikhail D Lukin. Quantum convolutional neural networks. Nature Physics , 15(12):1273-1278, 2019.\n- [31] Seunghyeok Oh, Jaeho Choi, and Joongheon Kim. A tutorial on quantum convolutional neural networks (qcnn). In 2020 International Conference on Information and Communication Technology Convergence (ICTC) , pages 236-239. IEEE, 2020.\n- [32] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010.\n- [33] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. CoRR , abs/1708.07747, 2017.\n- [34] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced research).\n- [35] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition, 2015.\n- [36] Jeremy Howard and Sylvain Gugger. Fastai: A layered api for deep learning. Information , 11(2):108, Feb 2020.\n- [37] Quantum edge detection - qhed algorithm on small and large images. Qiskit Documentation .\n- [38] Ruchipas Bavontaweepanya. Effect of depolarizing noise on entangled photons. In Journal of Physics: Conference Series , volume 1144, page 012047. IOP Publishing, 2018.\n## Numerical Simulation of the Time-Dependent SchrÂ¨dinger o Equation Using the Crank-Nicolson Method\n\nAdib Kabir\n\nMay 10, 2024\n\n## Abstract\nThis study presents a numerical simulation of a quantum electron confined in a 10 nm potential well, employing the Crank-Nicolson numerical technique to solve the time-dependent SchrÂ¨dinger o equation. Our results capture the evolution of the electron's wavefunction at the 2000th time step, illustrating distinct standing wave patterns and probability densities that validate quantum mechanical predictions. Additionally, both 2D and 3D simulations across multiple time steps reveal the dynamic nature of quantum superposition and interference within the well. These findings underscore the method's stability and accuracy, offering a robust tool for exploring quantum phenomena in constrained quantum systems\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Numerical_Simulation_of_the_Time-Dependent_Schrodinger_Equation_Using_the_Crank-Nicolson_Method - https://arxiv.org/abs/2410.10060\n[2] Quantum_Image_Processing - https://arxiv.org/abs/2203.01831\n[3] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[4] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç èƒ½å¦ä¸é‡å­ä¸­ç»§å™¨ç»“åˆï¼Œå®ç°é•¿è·ç¦»é‡å­é€šä¿¡ä¸­çš„é”™è¯¯çº æ­£ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¦‚ä½•å°†è¡¨é¢ç çš„çº é”™èƒ½åŠ›æ‰©å±•åˆ°å¤šä½“é‡å­ç³»ç»Ÿï¼ˆå¦‚é‡å­æ¨¡æ‹Ÿå™¨ä¸­çš„é›†ä½“é”™è¯¯ï¼‰ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç çš„é€»è¾‘é‡å­æ¯”ç‰¹èƒ½å¦æ”¯æŒé€šç”¨é‡å­é—¨æ“ä½œï¼Ÿå®¹é”™é€»è¾‘é—¨çš„æ„é€ åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\næ–°å‹ç¼–ç æ–¹æ¡ˆï¼ˆå¦‚ä¸‰ç»´è¡¨é¢ç æˆ–å…¨æ¯çº é”™ç ï¼‰æ˜¯å¦å¯èƒ½çªç ´äºŒç»´è¡¨é¢ç çš„æ€§èƒ½é™åˆ¶ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè–›å®šè°”æ–¹ç¨‹ï¼ˆæ—¶é—´ä¾èµ–å½¢å¼ï¼‰ä¸­ï¼Œè™šæ•°å•ä½ \\( i \\) çš„å¼•å…¥æœ‰ä»€ä¹ˆç‰©ç†æ„ä¹‰ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨è–›å®šè°”æ–¹ç¨‹ \\( i\\hbar \\frac{\\partial}{\\partial t} |\\Psi(t)\\rangle = H |\\Psi(t)\\rangle \\) é‡Œï¼Œæ™®æœ—å…‹å¸¸æ•° \\( \\hbar \\) çš„æ•°å€¼å¤§å°å¯¹é‡å­æ€æ—¶é—´æ¼”åŒ–æœ‰æ€æ ·çš„å½±å“ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo address the issue of circuit depth, variational time evolution (VTE) quantum algorithms were proposed. For a comprehensive overview see for instance Refs. [26, 27]. Relying on an iterative exchange of information between a classical and a quantum computer, these algorithms allow to work with shallower quantum circuits of constant depth in time. In particular, Li and Benjamin [28] first showed how to use a variational principle to simulate the real time dynamics of quantum systems and applied it to a quantum Ising model.\n## 2 Wavepacket dynamics in position space\n\nIn this work, we study the wavepacket dynamics governed by the time-dependent SchrÃ¶dinger equation (TDSE)\n$$i \\hbar { \\frac { \\partial } { \\partial t } } \\psi ( x, t ) = H ( x ) \\, \\psi ( x, t ) \\quad \\quad ( 1 )$$\nwhere x is a spacial dimension mapped here to a one or two-dimensional grid. The wavefunction is normalized, âˆ« | Ïˆ x, t ( ) | 2 dx = 1 , so that the | Ïˆ x, t ( ) | 2 becomes the probability probability for finding the system at position x of the grid at time t . The time variable is considered as a continuous parameter. The Hamiltonian in Eq. (1) is given by\n$$H ( x ) = - \\frac { \\hbar { ^ } { 2 } } { 2 m } \\nabla ^ { 2 } + V ( x ) \\quad \\quad ( 2 )$$\nHere, -e and g n â‰ˆ 3 826 are the electron charge and the neutron . g -factor, respectively, P âŠ¥ ( q ) is the 3 Ã— 3 matrix, P âŠ¥ Î±Î² ( q ) = Î´ Î±Î² -q Î± Î² q /q 2 (with Î±, Î² = x, y, z ), which is a projector on to the plane perpendicular to the direction of q , and Ï‡ ( q q , ; Ï‰ ) is the 3 Ã— 3 spin susceptibility matrix (see, e.g., Sec. 5.7 in Ref. [45]). The poles of S ( q , Ï‰ ) occur at frequencies of magnons and Stoner excitations. This quantity is accessible from linear-response theory, and in the following we will show how it can be computed efficiently using the LL approach to TDDFpT. Hereafter, Hartree atomic units will be used, and the formalism is presented for insulating systems while the generalization to metals can be found in Appendix B of Ref. [46] and in Ref. [47].\n## 2.2. Time-dependent density-functional perturbation theory\n\nMagnetic excitations in solids can be modeled using the time-dependent Pauli-type Kohn-Sham (KS) equations of TDDFT that read:\n$$i \\frac { \\partial \\Psi _ { n, k } ( \\mathbf r, t ) } { \\partial t } = \\hat { H } ( t ) \\Psi _ { n, k } ( \\mathbf r, t ), \\quad \\quad \\quad$$\nwhere n and k are the electronic band index and the crystal momentum, respectively, Î¨ n, k ( r , t ) are the twocomponent time-dependent KS spinor wave functions, and Ë† ( H t ) is the time-dependent Hamiltonian operator of the system [48]. It is often convenient to use perturbation theory to first order within TDDFT (i.e. TDDFpT) what is also known as the linear-response TDDFT. Moreover, Eq. (3) is often solved in the frequency domain rather than in the time domain. Therefore, it can be shown that but linearizing Eq. (3) and by making a Fourier transform from the time domain to the frequency domain we can obtain the following set of the so-called resonant and anti-resonant Pauli-type linear-response KS (Sternheimer) equations [46, 47]:\n$$\\left ( \\hat { H } ^ { \\circ } _ { k + q } - \\varepsilon ^ { \\circ } _ { n, k } - \\omega \\right ) \\tilde { U } ^ { \\prime } _ { n, k + q } ( \\$$\nThe classical field Ïˆ ( r , t ) varies slowly in time and space and satisfies a non-linear SchrÂ¨dinger o equation, the so called Gross-Pitaevskii Equation (GPE)\n$$H = \\int \\mathcal { H } d ^ { 3 } \\mathbf r = \\int \\left [ \\frac { \\hslash ^ { 2 } } { 2 m } \\nabla \\psi ( \\mathbf r, t ) \\cdot \\nabla \\psi ^ { * } ( \\mathbf r, t ) + \\frac { \\lambda } { 2 } | \\psi ( \\mathbf r, t ) | ^ { 4 } \\right ] d ^ { 3 } \\mathbf r, \\\\ \\mathrm \\leqslant \\| \\psi ( \\mathbf r, t ) \\| \\text {varies slowly in time and space and satisfies a non-linear Schrodinger$$\n$$i \\hbar { \\frac { \\partial } { \\partial t } } \\psi ( \\mathbf r, t ) = \\frac { \\delta H } { \\delta \\psi ^ { * } ( \\mathbf r, t ) } = - \\frac { \\hbar { ^ } { 2 } } { 2 m } \\nabla ^ { 2 } \\psi ( \\mathbf r, t ) + \\lambda | \\psi ( \\mathbf r, t ) | ^ { 2 } \\psi ( \\mathbf r, t ). \\quad \\quad ( 4 ) \\ \\\\ \\tan, i t i s e a s y \\, to \\, \\mathrm o b t a n { c o n s e v a t i o n } \\, { \\mathrm a w s a t i o n } \\, { \\mathrm a t i c l e }$$\n( ) From this equation, it is easy to obtain conservation laws about the particle number, energy and momentum\n$$\\frac { \\partial } { \\partial t } \\rho + \\nabla \\cdot j = 0, \\\\ \\frac { \\partial } { 3 } \\mathcal { H } + \\nabla \\cdot \\vec { \\mathcal { P } } = 0,$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] turboMagnon_--_A_code_for_the_simulation_of_spin-wave_spectra_using_the_Liouville-Lanczos_approach_to_time-dependent_density-functional_perturbation_theory - https://arxiv.org/abs/2203.01120\n[2] A_topological_realization_of_spin_polarization_through_vortex_formation_in_collisions_of_Bose-Einstein_condensates - https://arxiv.org/abs/2202.13300\n[3] Quantum_algorithms_for_grid-based_variational_time_evolution - https://arxiv.org/abs/2203.02521\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå“ˆå¯†é¡¿ç®—ç¬¦ \\( H \\) åœ¨ä¸åŒçš„é‡å­ç³»ç»Ÿï¼ˆå¦‚æ°¢åŸå­ã€å¤šç”µå­åˆ†å­ï¼‰ä¸­å…·ä½“å½¢å¼æ˜¯å¦‚ä½•ç¡®å®šçš„ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¯¹äºç»™å®šçš„ç®€å•é‡å­ç³»ç»Ÿï¼ˆå¦‚ä¸€ç»´æ— é™æ·±åŠ¿é˜±ï¼‰ï¼Œå¦‚ä½•ä»è–›å®šè°”æ–¹ç¨‹æ¨å¯¼å‡ºå…¶é‡å­æ€ \\( |\\Psi(t)\\rangle \\) çš„å…·ä½“è¡¨è¾¾å¼ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\n## B The time-dependent variational principle in first and second quantization\nThe variational approach to quantum dynamics aims to approximate the solution of the TDSE on a low-dimensional submanifold of the full Hilbert space. The trial wavefunction defined on this manifold | Ïˆ ( Î¸ ( )) t ã€‰ is parameterized by a set of n p time-dependent parameters, Î¸ ( ) t = { Î¸ 1 ( ) t , ..., Î¸ n p ( ) t } . A time-dependent variational principle (TDVP) defines the optimal evolution of the parameters within the submanifold of the full Hilbert space. There exist different formulations of the TDVP. For KÃ¤hler manifolds, i. e., when the tangent space is a complex subspace [34], all the different formulations lead to the same equations of motion for the variational parameters. However, this is not the case for unitary parameterizations of the type\n$$| \\psi ( \\theta ( t ) ) \\rangle = U ( \\theta ( t ) ) \\, | \\phi \\rangle \\,,$$\nwhere | Ï† ã€‰ is a reference state and U ( Î¸ ( )) t is a unitary operator (e.g., the quantum circuit) depending on real parameters Î¸ ( ) t [34]. In this case, the equations of motion differ and hold distinct properties such as the conservation of the norm or the energy. Recent works [26, 31, 32, 33, 34] promoted the use of the equations of motion derived from the McLachlan variational principle due to of their higher numerical stability [34]. For a given Hamiltonian H , these equations, when accounting for a global phase mismatch (see Ref. [26] for a thorough derivation), read\n$$\\mathrm F \\dot { \\theta } = V \\,,$$\n\nwith\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_algorithms_for_grid-based_variational_time_evolution - https://arxiv.org/abs/2203.02521\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨é‡å­æ€æ—¶é—´æ¼”åŒ–æ¨¡æ‹Ÿä¸­ï¼Œè–›å®šè°”æ–¹ç¨‹æ•°å€¼æ±‚è§£çš„å¸¸ç”¨ç®—æ³•æœ‰å“ªäº›ï¼Œå®ƒä»¬å„è‡ªçš„ä¼˜ç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå½“å°†è–›å®šè°”æ–¹ç¨‹åº”ç”¨äºé‡å­åŒ–å­¦è®¡ç®—ä¸­çš„åˆ†å­åŠ¨åŠ›å­¦æ—¶ï¼Œå¦‚ä½•å¤„ç†åˆ†å­ä¸­åŸå­æ ¸ä¸ç”µå­çš„ç›¸äº’ä½œç”¨åœ¨æ–¹ç¨‹ä¸­çš„ä½“ç°ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè–›å®šè°”æ–¹ç¨‹çš„è§£ \\( |\\Psi(t)\\rangle \\) çš„å½’ä¸€åŒ–æ¡ä»¶æ˜¯ä»€ä¹ˆï¼Œåœ¨å®é™…è®¡ç®—ä¸­å¦‚ä½•ä¿è¯å…¶å½’ä¸€åŒ–ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nä»è–›å®šè°”æ–¹ç¨‹å‡ºå‘ï¼Œå¦‚ä½•è§£é‡Šé‡å­ç³»ç»Ÿä¸­çš„éš§ç©¿æ•ˆåº”ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨å¤šä½“é‡å­ç³»ç»Ÿä¸­ï¼Œè–›å®šè°”æ–¹ç¨‹çš„å½¢å¼ä¼šå‘ç”Ÿæ€æ ·çš„å˜åŒ–ä»¥æè¿°ç²’å­é—´çš„ç›¸äº’ä½œç”¨ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè–›å®šè°”æ–¹ç¨‹ï¼ˆæ—¶é—´ä¾èµ–å½¢å¼ï¼‰ä¸ä¸å«æ—¶è–›å®šè°”æ–¹ç¨‹ä¹‹é—´æœ‰æ€æ ·çš„è”ç³»å’ŒåŒºåˆ«ï¼Ÿå¦‚ä½•ä»å‰è€…æ¨å¯¼å‡ºåè€…ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨é‡å­æ€æ—¶é—´æ¼”åŒ–è¿‡ç¨‹ä¸­ï¼Œæ³¢å‡½æ•° \\( |\\Psi(t)\\rangle \\) çš„ç›¸ä½å˜åŒ–æœ‰ä»€ä¹ˆç‰©ç†æ„ä¹‰ï¼Œåœ¨è–›å®šè°”æ–¹ç¨‹ä¸­æ˜¯å¦‚ä½•ä½“ç°çš„ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè‹¥å¯¹ä¸€ä¸ªé‡å­ç³»ç»Ÿæ–½åŠ å¤–éƒ¨æ—¶å˜çš„å¾®æ‰°ï¼Œè–›å®šè°”æ–¹ç¨‹åº”å¦‚ä½•ä¿®æ­£ä»¥æè¿°è¿™ç§æƒ…å†µï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨é‡å­å…‰å­¦é¢†åŸŸï¼Œè–›å®šè°”æ–¹ç¨‹å¦‚ä½•ç”¨äºæè¿°å…‰ä¸ç‰©è´¨ç›¸äº’ä½œç”¨è¿‡ç¨‹ä¸­çš„é‡å­æ€æ¼”åŒ–ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nä»æ•°å­¦è§’åº¦çœ‹ï¼Œè–›å®šè°”æ–¹ç¨‹ä¸­çš„åå¯¼æ•° \\( \\frac{\\partial}{\\partial t} \\) å¯¹æ±‚è§£é‡å­æ€çš„æ—¶é—´æ¼”åŒ–å¸¦æ¥äº†å“ªäº›æŒ‘æˆ˜ï¼Œæœ‰å“ªäº›æ•°å­¦æŠ€å·§å¯ç”¨äºå…‹æœè¿™äº›æŒ‘æˆ˜ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\n- Â· u ( t, x ) is the velocity field,\n- Â· p t, ( x ) is the pressure field,\n- Â· Î½ is the kinematic viscosity of the fluid,\n- Â· âˆ† is the Laplacian operator, representing the diffusion of momentum,\n- Â· f ( t, x ) represents external body forces acting on the fluid.\nThe coupling of the quantum-inspired operator with the Navier-Stokes equations is designed to incorporate quantum effects into the classical fluid dynamics framework. The modified Navier-Stokes equations with the SchrÂ¨dinger-like operator can o be formulated as follows:\n$$\\frac { \\partial \\mathbf u } { \\partial t } + ( \\mathbf u \\cdot \\nabla ) \\mathbf$$\n\nwhere:\n- Â· i /planckover2pi1 2 m âˆ† u is the quantum correction term that introduces the influence of quantum mechanics into the fluid model,\n- Â· V ( u ) is a nonlinear potential that depends on the velocity field, modeling interactions and dissipation mechanisms at small scales.\nThis coupling provides a framework for understanding the interplay between classical fluid dynamics and quantum mechanics.\n\n## 3.6.1 Analysis of the Coupling Terms\nFuture work will explore the numerical implementation of the fractional quantuminspired model and the development of machine learning techniques to optimize the parameters /planckover2pi1 and Î± based on real-world data from turbulent flows.\n## 3.6 Coupling with Navier-Stokes Equations\n\nThe Navier-Stokes equations govern the motion of incompressible viscous fluids. They are expressed as follows:\n$$\\frac { \\partial \\mathbf u } { \\partial t } + ( \\mathbf u \\cdot \\nabla ) \\mathbf u = - \\nabla p + \\nu \\Delta \\mathbf u + \\mathbf f,$$\n\nwhere:\nConsider the following evolutionary partial differential equation (PDE) on a d -dimensional unit cube\n$$\\partial _ { t } u ( t, x ) = a \\Delta u ( t, x ) + b \\nabla \\cdot u ( t, x ) + c ( t, x ) u ( t, x ) + f ( t, x ), \\ t \\in [ 0, T ], \\ x \\in [ 0, 1 ] ^ { d }, \\quad \\quad ( 1 9 1 ) \\$$\n\n$$u ( 0, x ) = u _ { 0 } ( x ), \\ \\ x \\in [ 0, 1 ] ^ { d },$$\n$$u ( t, x ) = 0, \\ \\ x \\in \\partial ( | 0, 1 | ^ { d } ).$$\nHere a &gt; 0 is a positive parameter called the thermal diffusivity, b is a real parameter called the flow velocity, c t, x ( ) â‰¤ 0 is the potential function, and f ( t, x ) is the source term. We impose homogeneous Dirichlet boundary condition on the cube, so the heat process is dissipative.\nA standard way of solving Eq. (191) numerically is by the method of lines, which first semi-discretizes the PDE into an ODE by only performing spatial discretization then solves the resulting ODE by any time propagator. For spatial discretization, along each direction we use ( n x +1) many equi-distant grid points j/n x , 0 â‰¤ j â‰¤ n x . We discretize the spatial derivatives by central difference, and the semi-discretized heat equation is given as\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum-Inspired_Stochastic_Modeling_and_Regularity_in_Turbulent_Fluid_Dynamics - https://arxiv.org/abs/2410.13154\n[2] Fast-forwarding_quantum_algorithms_for_linear_dissipative_differential_equations - https://arxiv.org/abs/2410.13189\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨é‡å­è®¡ç®—ä¸­ï¼Œå¦‚ä½•åˆ©ç”¨è–›å®šè°”æ–¹ç¨‹æ¨¡æ‹Ÿé‡å­æ¯”ç‰¹çš„çŠ¶æ€éšæ—¶é—´çš„å˜åŒ–ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¯¹äºå¤æ‚çš„é‡å­ç³»ç»Ÿï¼Œè–›å®šè°”æ–¹ç¨‹çš„ç²¾ç¡®è§£å¾€å¾€éš¾ä»¥è·å¾—ï¼Œå¸¸ç”¨çš„è¿‘ä¼¼æ±‚è§£æ–¹æ³•æœ‰å“ªäº›ï¼Œå…¶ç†è®ºä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè–›å®šè°”æ–¹ç¨‹ä¸­çš„å“ˆå¯†é¡¿ç®—ç¬¦ \\( H \\) ä¸ç³»ç»Ÿçš„èƒ½é‡æœ¬å¾å€¼å’Œæœ¬å¾æ€æœ‰æ€æ ·çš„å…³ç³»ï¼Œå¦‚ä½•é€šè¿‡è–›å®šè°”æ–¹ç¨‹æ±‚è§£å®ƒä»¬ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nåœ¨æè¿°é‡å­ç³»ç»Ÿçš„é€€ç›¸å¹²è¿‡ç¨‹ä¸­ï¼Œè–›å®šè°”æ–¹ç¨‹éœ€è¦è¿›è¡Œæ€æ ·çš„æ‹“å±•æˆ–ä¿®æ­£ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè‹¥è€ƒè™‘ç›¸å¯¹è®ºæ•ˆåº”ï¼Œè–›å®šè°”æ–¹ç¨‹ä¼šå‘ç”Ÿæ€æ ·çš„å˜åŒ–ï¼Œæ–°çš„æ–¹ç¨‹åœ¨å¤„ç†é«˜é€Ÿè¿åŠ¨çš„é‡å­ç²’å­æ—¶ä¸åŸæ–¹ç¨‹æœ‰ä½•ä¸åŒï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nä»è–›å®šè°”æ–¹ç¨‹çš„è§’åº¦ï¼Œå¦‚ä½•ç†è§£é‡å­ç³»ç»Ÿä¸­çš„çº ç¼ æ€åŠå…¶éšæ—¶é—´çš„æ¼”åŒ–ç‰¹æ€§ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\næ³¢å‡½æ•°æ¼”åŒ–å›¾ï¼ˆå¦‚è–›å®šè°”æ–¹ç¨‹è§£çš„å¯è§†åŒ–ï¼‰å¦‚ä½•ç›´è§‚å±•ç¤ºé‡å­å åŠ æ€çš„åŠ¨æ€è¡Œä¸ºï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå›¾è¡¨ä¸­æ³¢å‡½æ•°çš„æ¨¡å¹³æ–¹ï¼ˆ\\(|\\psi(x,t)|^2\\)ï¼‰ä¸æ¦‚ç‡å¯†åº¦åˆ†å¸ƒæœ‰ä½•å¯¹åº”å…³ç³»ï¼Ÿå®éªŒä¸­å¦‚ä½•é€šè¿‡æµ‹é‡éªŒè¯è¿™ä¸€å…³ç³»ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nThis definition is then extended to the set of all density operators by the convex roof extension method described in Equation (1). It has been proven that the entanglement entropy is norm continuous on H [10], and so the infimum, (OPSE), is always achieved in this case.\nAnother example of entanglement measurement formed in the same way is the Tsallis entanglement entropy T 2 , which is defined by\n$$T _ { 2 } ( | \\psi \\rangle ( \\psi | ) = 1 - T r \\left ( ( T r _ { \\mathcal { A } } ( | \\psi \\rangle ( \\psi | ) ) ^ { 2 } \\right )$$\nfor all pure states | Ïˆ ã€‰ âˆˆ H = AâŠ—B . It is then extended to general mixed states Ï of H via the convex roof construction given in Equation (1), namely\n$$T _ { 2 } ( \\rho ) = \\inf \\left \\{ \\sum _ { i = 0 } ^ { \\infty } p _ { i } T _ { 2 } ( | \\psi _ { i } \\rangle \\langle \\psi _ { i } | ) \\, \\colon \\{ \\{ p _ { i } \\} _ { i = 0 } ^ { \\infty }, \\{ \\psi _ { i } \\} _ { i = 0 } ^ { \\infty } \\} \\in \\mathcal { C D } ( \\rho ) \\right \\} \\quad ( 5 )$$\n## B The time-dependent variational principle in first and second quantization\nThe variational approach to quantum dynamics aims to approximate the solution of the TDSE on a low-dimensional submanifold of the full Hilbert space. The trial wavefunction defined on this manifold | Ïˆ ( Î¸ ( )) t ã€‰ is parameterized by a set of n p time-dependent parameters, Î¸ ( ) t = { Î¸ 1 ( ) t , ..., Î¸ n p ( ) t } . A time-dependent variational principle (TDVP) defines the optimal evolution of the parameters within the submanifold of the full Hilbert space. There exist different formulations of the TDVP. For KÃ¤hler manifolds, i. e., when the tangent space is a complex subspace [34], all the different formulations lead to the same equations of motion for the variational parameters. However, this is not the case for unitary parameterizations of the type\n$$| \\psi ( \\theta ( t ) ) \\rangle = U ( \\theta ( t ) ) \\, | \\phi \\rangle \\,,$$\nwhere | Ï† ã€‰ is a reference state and U ( Î¸ ( )) t is a unitary operator (e.g., the quantum circuit) depending on real parameters Î¸ ( ) t [34]. In this case, the equations of motion differ and hold distinct properties such as the conservation of the norm or the energy. Recent works [26, 31, 32, 33, 34] promoted the use of the equations of motion derived from the McLachlan variational principle due to of their higher numerical stability [34]. For a given Hamiltonian H , these equations, when accounting for a global phase mismatch (see Ref. [26] for a thorough derivation), read\n$$\\mathrm F \\dot { \\theta } = V \\,,$$\n\nwith\n$$H _ { C } = \\sum _ { z \\in \\{ 0, 1 \\} ^ { n } } C ( z ) | z \\rangle \\langle z |$$\nin terms of local terms, and a parametrized family { U G ( Î¸ ) } Î¸ âˆˆ Î˜ of n -qubit unitary circuits. The later might be parametrized by the underlying graph of the cost function or in case of hardware-efficient algorithms tailored to the physical device [12]. The parametrized family give rise to variational ansatz states\n$$| \\Psi ( \\theta ) \\rangle = U _ { G } ( \\theta ) | 0 \\rangle ^ { \\otimes n } \\,.$$\nthat can be prepared with U G ( Î¸ ) from a product state | 0 ã€‰ âŠ— n . Measuring Î¨( ) in the Î¸ computational basis then provides a sample z âˆˆ { 0 1 , } n from the distribution p z ( ) = |ã€ˆ z | Î¨( ) Î¸ ã€‰| 2 such that the expectation value of the associated cost function is equal to the energy E [ C z ( )] = ã€ˆ Î¨( ) Î¸ | H C | Î¨( ) Î¸ ã€‰ of the state Î¨( Î¸ ) with respect to H C . Thus the problem of maximizing C is translated to that of finding a value of the (vector of) parameters Î¸ maximizing the energy of Î¨( Î¸ ). The latter step is envisioned to be performed e.g., by numerical gradient descent or a similar classical procedure prescribing (iteratively) what parameters Î¸ to try. The computation of this prescription (according to obtained measurement results) is the classical processing part of the quantum algorithm leading to the term hybrid . We will refer to this form of algorithm as a 'bare' hybrid algorithm in the following.\nThe potential utility of this approach hinges on a number of factors. Of primary importance - beyond questions of convergence or efficiency - is whether the family { Î¨( ) Î¸ } Î¸ âˆˆ Î˜ of\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] A_Variational_Quantum_Algorithm_For_Approximating_Convex_Roofs - https://arxiv.org/abs/2203.02099\n[2] Quantum_algorithms_for_grid-based_variational_time_evolution - https://arxiv.org/abs/2203.02521\n[3] Twisted_hybrid_algorithms_for_combinatorial_optimization - https://arxiv.org/abs/2203.00717\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¤šä½“ç³»ç»Ÿçš„æ³¢å‡½æ•°åœ¨å›¾è¡¨ä¸­å¦‚ä½•è¡¨ç¤ºï¼Ÿä¾‹å¦‚ï¼ŒäºŒç»´ç½‘æ ¼ä¸­é‡å­æ¯”ç‰¹çš„çº ç¼ æ€å¦‚ä½•é€šè¿‡å›¾å½¢ç¬¦å·åŒ–ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­æ€çš„å¸ƒæ´›èµ«çƒè¡¨ç¤ºä¸æ³¢å‡½æ•°æ¼”åŒ–å›¾åœ¨æè¿°é‡å­ç‰¹æ€§æ—¶æœ‰ä½•äº’è¡¥æ€§ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­æ€å±‚ææˆåƒçš„ç»“æœå¦‚ä½•é€šè¿‡å›¾è¡¨åæ¨å¯†åº¦çŸ©é˜µï¼Ÿè¯¯å·®æ¡åœ¨å›¾è¡¨ä¸­å¦‚ä½•ä½“ç°ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nThe resulting fit parameters are listed in Tab. (SI) 1. The dipole moment is slightly higher for VSi 2, compared to VSi 1, which we attribute to effects not covered by our electric field simulation, like e.g., screening effects leading to local inhomogeneities of the electric field.\n| (a)   | ğ‘ğ· = 7 Ã— 10 14 ğ‘ğ‘š -3   | ğ‘ğ· = 7 Ã— 10 14 ğ‘ğ‘š -3   | ğ‘ğ· = 7 Ã— 10 14 ğ‘ğ‘š -3   |\n|-------|------------------------|------------------------|------------------------|\n|       | ğ‘‘  ( ğ‘€ğ‘‰/ğ‘š )            | ğºğ»ğ‘§                    | ğ‘“ 0  (ğºğ»ğ‘§)             |\n| VSi 1 | -5.08 Â± 0.14           | ( ğ‘€ğ‘‰ ) ğ‘š -0.05 Â± 0.01  | -14.35 Â± 1.00          |\n| VSi 2 | -5.15 Â± 0.41           | -0.06 Â± 0.03           | -3.90 Â± 1.38           |\n| (b)   | ğ‘ğ· = 9 Ã— 10 14 ğ‘ğ‘š -3   | ğ‘ğ· = 9 Ã— 10 14 ğ‘ğ‘š -3   | ğ‘ğ· = 9 Ã— 10 14 ğ‘ğ‘š -3   |\n|-------|------------------------|------------------------|------------------------|\n|       | ğºğ»ğ‘§ ğ‘€ğ‘‰/ğ‘š )             |                        | ğ‘“ 0  (ğºğ»ğ‘§)             |\n|       | ğºğ»ğ‘§ ğ‘€ğ‘‰/ğ‘š )             | ğºğ»ğ‘§                    | ğ‘“ 0  (ğºğ»ğ‘§)             |\n|       | ğºğ»ğ‘§ ğ‘€ğ‘‰/ğ‘š )             | ğ›¼  ( ( ğ‘€ğ‘‰ ) 2 )        |                        |\n|       | ğºğ»ğ‘§ ğ‘€ğ‘‰/ğ‘š )             | ğ‘š                      |                        |\n| VSi 1 | -4.21 Â± 0.15           | -0.09 Â± 0.01           | -7.73 Â± 0.96           |\n| (c)   | ğ‘ğ· = 11 Ã— 10 14 ğ‘ğ‘š -3   | ğ‘ğ· = 11 Ã— 10 14 ğ‘ğ‘š -3   | ğ‘ğ· = 11 Ã— 10 14 ğ‘ğ‘š -3   |\n|-------|-------------------------|-------------------------|-------------------------|\n|       | ğ‘‘  ( ğºğ»ğ‘§ ğ‘€ğ‘‰/ğ‘š )         | ğºğ»ğ‘§                     | ğ‘“ 0  (ğºğ»ğ‘§)              |\n| VSi 1 | -3.46 Â± 0.10            | ( ğ‘€ğ‘‰ ) ğ‘š -0.11 Â± 0.01   | -0.49 Â± 0.61            |\n| VSi 2 | -6.71 Â± 0.39            | 0.03 Â± 0.03             | 1.46 Â± 1.36             |\nTable (SI) 1: Dipole moments ğ‘‘ and polarizabilities ğ›¼ extracted via the fit of ğ›¥ğ‘“ ğ´1 from the Stark shift measurements shown in Fig. (SI) 3 for different considered doping concentrations in the intrinsic layer.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_enhanced_electric_field_mapping_within_semiconductor_devices - https://arxiv.org/abs/2410.10750\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè´å°”æ€åˆ¶å¤‡å®éªŒæ•°æ®ï¼ˆå¦‚é“¾æ¥å›¾è¡¨ï¼‰ä¸­çš„ä¿çœŸåº¦æ›²çº¿å¦‚ä½•åæ˜ é‡å­é—¨æ“ä½œçš„ç²¾åº¦ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né€€ç›¸å¹²è¿‡ç¨‹åœ¨å›¾è¡¨ä¸­å¦‚ä½•é‡åŒ–ï¼Ÿä¾‹å¦‚ï¼Œç›¸å¹²æ—¶é—´çš„è¡°å‡æ›²çº¿å¦‚ä½•é€šè¿‡æŒ‡æ•°æ‹Ÿåˆåˆ†æï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¡¨é¢ç çš„çº é”™æ€§èƒ½ï¼ˆå¦‚é”™è¯¯ç‡éšç è·å˜åŒ–ï¼‰å¦‚ä½•é€šè¿‡çƒ­åŠ›å›¾æˆ–ç­‰é«˜çº¿å›¾å±•ç¤ºï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nT-carbon çš„èƒ½å¸¦ç»“æ„å›¾è¡¨å¦‚ä½•æ­ç¤ºå…¶æ‹“æ‰‘ç‰¹æ€§ï¼Ÿä¸çŸ³å¢¨çƒ¯çš„èƒ½å¸¦å›¾æœ‰ä½•å…³é”®åŒºåˆ«ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nWe are going to use the default PauliNet architecture and change the basis set to the correlation-consistent family [60], starting from cc-pvdz to cc-pv5z. The first step is to define a Molecule object (for example named LiH ) with the geometry of LiH at an internuclear distance of 3 0141132 Bohr, and a total zero . charge and spin. Then, the PauliNet neural network can be initialized for a given basis set, say ccpvdz, from a Hartree-Fock calculation using the function from hf(LiH, basis='cc-pvdz') , meaning that the ansatz contains a single Slater determinant (cfr. Equation (33)) and uses the HF orbitals. After initialization, the network can be trained using the function train(net) , where net is the neural network object returned from the initialization procedure. This is the most expensive part of the calculation, however, the training parameters can be slightly modified to decrease the computation time, and still obtain reasonably optimized network weights (with an uncertainty of around 1 m E h ). We suggest you to use n steps = 500 , batch size = 500 and epoch size = 20 . The last step to obtain the ground state energy of LiH is to call the function evaluate(net) . Similarly to train(net) , evaluate(net) accepts optional parameters defining the number of Monte Carlo sweeps and the length of the Markov chain sampled at each step. For these two, we suggest the following values, n steps = 400 and sample size\n= 800 . Save the obtained energy and the estimated error, and repeat the same process for the other basis sets. The choice of training parameters was such that the optimization does not take too long time. If you want to investigate the effects of the training procedure on the final energy and uncertainty, as an advanced exercise you can modify the values of n steps and batch size in the train(net) function (hint: modify one value at a time to understand their role).\n## 3.2.2 CCSD(T) calculations\nIn this part we are going to perform CCSD(T) calculations in combination with the four basis sets used above. You can use PySCF for performing these calculations, and they should take significantly less time than the PauliNet ones. PySCF has a pretty extensive user guide available online at https://pyscf.org/, with many examples. We suggest you to have a look at it if you get stuck at any point. The first step is again to define the lithium hydride molecule, this time in a data-structure that PySCF understands. This can be done with the function gto.M(...) , which accepts a number of arguments similar to the construction of the Molecule object for the DeepQMC package. Then, you can create a restricted HF instance with rhf = scf.RHF(mol) , where mol is the molecule you just created (hint: make sure to set the correct basis set with mol.basis = 'cc-pvdz' and build it with mol.build() ). The rhf object can be used to create the coupled cluster instance with cc = cc.CCSD(rhf) . The energy for each method can then be obtained by calling .kernel() on the HF and coupled cluster objects, and .ccsd t() for the perturbative triples correction. Save all these energies and repeat the process for all basis sets. If you have a powerful computer, as an additional exercise you can try to compute the full CI energy, however, you will probably be able to get it at most with the triple zeta basis set (hint: for such a small molecule, the CCSD(T) and FCI energies are very similar).\n## 3.2.3 Comparison of PauliNet and CCSD(T)\nIn P. Smolensky (1990), the author suggests using a representation based on tensor product :   Tensor   Product   Representation   (TPR),   to   capture   syntactic bindings across sentences. [49, 50] Tensor product is here understood as the Kronecker product, denoted by . Given two matrices A, B we define A B to be âŠ— âŠ— the block matrix where every element of A is multiplied by B (Fig. 2.1). TPR is a structure where every unit of a sentence can be part of the representation of every constituent. It can be compositionally encoded from the numerical vectors representing the composing words, and hence offers the ideal framework to build-up a structure to embed not only words, but also sentences.\n$$\\begin{array} { c c c } a _ { 1 1 } B & \\cdots & a _ { 1 n } B \\\\ \\vdots & \\ddots & \\vdots \\\\ a _ { m 1 } B & \\cdots & a _ { m n } B \\end{array}$$\nBased on Lambek's pregroup algebra, in Mehrnoosh et al. (2010), the authors introduce the CSC algorithm, which develops another implementation of tensor based representation of the meaning of a sentence. [34] This algorithm can be implemented on a quantum computer. Let the linear map Î£âŸ¨ ii| (Fig. 2.2), which is the sum over all the basis vectors of the space N. We call this linear map a cap . It formally describes the state of log  EPR pairs (a generalization of n quantum entanglement). If the basis is of size n and is orthonormal, the cap can simply be thought of as a row vector of size n 2 , filled of 0, and valued 1 at the positions  ii|. The steps of the CSC algorithm are detailed in Fig. 2.3. âŸ¨\n$$\\sum _ { i } \\langle i | \\colon =$$\n\nFig. 2.2 (Zeng &amp; Coecke, 2016) : Definition of a cap\n- 1 Compute the tensor product words Wo wk in the order that each word appears in the sentence\n- 2 Construct a linear map that represents the grammatical type reduction by the vectors with the appropriate caps. For example, given that the pregroup type reduction of a nounhransitive verblnoun sentence is:\n- [21] T. Skovhus, T. Olsen, Dynamic transverse magnetic susceptibility in the projector augmented-wave method: Application to Fe, Ni, and Co, Phys. Rev. B 103 (2021) 245110.\n- [22] F. Aryasetiawan, K. Karlsson, Phys. Rev. B 60 (1999) 7419.\n- [23] K. Karlsson, F. Aryasetiawan, Phys. Rev. B 62 (2000) 3006.\n- [24] T. Kotani, M. van Schilfgaarde, J. Phys.: Condens. Matter 20 (2008) 295214.\n- [25] S Â¸ aÂ¸ioË˜lu, s g A. Schindlmayr, C. Friedrich, F. Freimuth, S.BlÂ¨gel, Phys. Rev. B 81 (2010) 054434. u\n- [26] M. MÂ¨ uller, C. Friedrich, S. BlÂ¨gel, Phys. Rev. B 94 (2016) 064433. u\n- [27] E. Runge, E. Gross, Phys. Rev. Lett. 52 (1984) 997.\n- [28] M. A. L. Marques, N. T. Maitra, F. M. S. Nogueira, E. K. U. Gross, A. Rubio (Eds.), Fundamentals of Time-Dependent Density Functional Theory, Vol. 837, Lecture Notes in Physics, Springer-Verlag, Berlin Heidelberg, 2012.\n- [29] S. Baroni, R. Gebauer, The Liouville-Lanczos Approach to Time-Dependent Density-Functional (Perturbation) Theory, Ref. [28], chapter 19, p. 375-390.\n- [30] D. Rocca, R. Gebauer, Y. Saad, S. Baroni, J. Chem. Phys. 128 (2008) 154105.\n- [31] I. Timrov, N. Vast, R. Gebauer, S. Baroni, Phys. Rev. B 88 (2013) 064301, ibid. 91 , 139901 (2015).\n- [32] S. Baroni, P. Giannozzi, A. Testa, Green's-function approach to linear response in solids, Phys. Rev. Lett. 58 (1987) 1861.\n- [33] S. Baroni, S. de Gironcoli, A. D. Corso, P. Giannozzi, Phonons and related crystal properties from densityfunctional perturbation theory, Rev. Mod. Phys. 73 (2) (2001) 515.\n- [34] O. MalcioiË˜lu, R. Gebauer, D. Rocca, S. Baroni, Comput. Phys. Commun. 182 (2011) 1744. g\n- [35] X. Ge, S. J. Binnie, D. Rocca, R. Gebauer, S. Baroni, turboTDDFT 2.0 - Hybrid functionals and new algorithms within time-dependent density-functional perturbation theory, Comput. Phys. Commun. 185 (2014) 2080.\n- [36] I. Timrov, N. Vast, R. Gebauer, S. Baroni, Comput. Phys. Commun. 196 (2015) 460.\n- [37] I. Timrov, M. Markov, T. Gorni, M. Raynaud, O. Motornyi, R. Gebauer, S. Baroni, N. Vast, Phys. Rev. B 95 (2017) 094301.\n- [38] O. Motornyi, N. Vast, I. Timrov, O. Baseggio, S. Baroni, A. Dal Corso, Phys. Rev. B 102 (2020) 035156.\n- [39] The GNU General Public License: http://www.gnu.org/licenses/gpl.html .\n- [40] P. Giannozzi, S. Baroni, N. Bonini, M. Calandra, R. Car, C. Cavazzoni, D. Ceresoli, G. Chiarotti, M. Cococcioni, I. Dabo, A. Dal Corso, S. De Gironcoli, S. Fabris, G. Fratesi, R. Gebauer, U. Gerstmann, C. Gougoussis, A. Kokalj, M. Lazzeri, L. Martin-Samos, N. Marzari, F. Mauri, R. Mazzarello, S. Paolini, A. Pasquarello, L. Paulatto, C. Sbraccia, S. Scandolo, G. Sclauzero, A. Seitsonen, A. Smogunov, P. Umari, R. Wentzcovitch, Quantum ESPRESSO: A modular and open-source software project for quantum simulations of materials, J. Phys.: Condens. Matter 21 (2009) 395502.\n- [41] P. Giannozzi, O. Andreussi, T. Brumme, O. Bunau, M. Buongiorno Nardelli, M. Calandra, R. Car, C. Cavazzoni, D. Ceresoli, M. Cococcioni, N. Colonna, I. Carnimeo, A. Dal Corso, S. de Gironcoli, P. Delugas, R. A. DiStasio Jr., A. Ferretti, A. Floris, G. Fratesi, G. Fugallo, R. Gebauer, U. Gerstmann, F. Giustino, T. Gorni, J. Jia, M. Kawamura, H.-Y. Ko, A. Kokalj, E. KÂ¨Â¸ cÂ¨kbenli, M. Lazzeri, M. Marsili, N. Marzari, F. Mauri, u u N. L. Nguyen, H.-V. Nguyen, A. Otero-de-la Rosa, L. Paulatto, S. PoncÂ´, D. Rocca, R. Sabatini, B. Santra, e M. Schlipf, A. Seitsonen, A. Smogunov, I. Timrov, T. Thonhauser, P. Umari, N. Vast, S. Baroni, Advanced capabilities for materials modelling with Quantum ESPRESSO, J. Phys.: Condens. Matter 29 (2017) 465901.\n- [42] P. Giannozzi, O. Baseggio, P. Bonf` a, D. Brunato, R. Car, I. Carnimeo, C. Cavazzoni, S. de Gironcoli, P. Delugas, F. Ferrari Ruffino, A. Ferretti, N. Marzari, I. Timrov, A. Urru, S. Baroni, Quantum ESPRESSO toward the exascale, J. Chem. Phys. 152 (2020) 154105.\n- [43] O. Halpern, M. Johnson, On the Magnetic Scattering of Neutrons, Phys. Rev. 55 (1939) 898.\n- [44] M. Blume, Polarization Effects in the Magnetic Elastic Scattering of Slow Neutrons, Phys. Rev. 130 (1963) 1670.\n- [45] W. Jones, N. H. March, Theoretical solid state physics, Volume 1, Courier Corporation, 1985.\n- [46] T. Gorni, I. Timrov, S. Baroni, Spin dynamics from time-dependent density functional perturbation theory, Eur. Phys. J. B 91 (2018) 249.\n- [47] T. Gorni, Spin-fluctuation spectra in magnetic systems: a novel approach based on tddft, Ph.D. thesis, Scuola Internazionale Superiore di Studi Avanzati (SISSA), Trieste, Italy (2016, http://hdl.handle.net/20.500. 11767/43342 ).\n- [48] We use a hat ' Ë† ' on top of letters to indicate operators (e.g. Ë† ), while these same operators in the coordinate V representation are written without the hat and with the explicit dependence on the position vector r [e.g. V ( r )]. Moreover, we use a tilde ' Ëœ ' to indicate a Fourier transform of various quantities from the time domain [e.g. V ( )] t to the frequency domain [e.g. Ëœ ( V Ï‰ )]. A combination of these two notations is often used in this work.\n- [49] With the upper case letter we denote a 2 Ã— 2 matrix potential, while with the lower case letter we denote scalar potentials.\n- [50] L. Kleinman, Phys. Rev. B 21 (1980) 2630.\n- [51] G. Bachelet, SchlÂ¨ter, Phys. Rev. B 25 (1982) 2103. u\n- [52] G. Bachelet, D. Hamann, SchlÂ¨ter, Phys. Rev. B 26 (1982) 4199. u\n- [53] L. Hemstreet, C. Fong, J. Nelson, Phys. Rev. B 47 (1993) 4238.\n- [54] D. Ceresoli, U. Gerstmann, A. Seitsonen, F. Mauri, Phys. Rev. B 81 (2010) 060409(R).\n- [55] N. Ashcroft, N. Mermin, Solid State Physics, Saunders College Publishing, Philadelphia, 1976.\n- [56] A. Dal Corso, Phys. Rev. B 82 (2010) 075116.\n- [57] We note that in the second term of Eq. (9) we symbolically mean a scalar product, while in the second term of Eq. (10) we symbolically mean a matrix-vector multiplication.\n- [58] These relations are a consequence of the fact that chargeand magnetization-density responses are real functions in space and time.\n- [59] N. Singh, P. Elliott, T. Nautiyal, J. K. Dewhurst, S. Sharma, Phys. Rev. B 99 (2019) 035151.\n- [60] S. Lehtola, M. Marques, Many recent density functionals are numerically unstable, arXiv:2206.14062 (2022).\n- [61] J. Sun, A. Ruzsinszky, J. Perdew, Phys. Rev. Lett. 115 (2015) 036402.\n- [62] M. Ekholm, D. Gambino, H. JÂ¨ onsson, F. TasnÂ´di, B. Alling, I. Abrikosov, Assessing the SCAN functional a for itinerant electron ferromagnets, Phys. Rev. B 98 (2018) 094413.\n- [63] F. Tran, G. Baudesson, J. Carrete, G. Madsen, P. Blaha, K. Schwarz, D. Singh, Shortcomings of meta-GGA functionals when describing magnetism, Phys. Rev. B 102 (2020) 024407.\n- [64] T. Skovhus, T. Olsen, H. Ronnow, arXiv:2110.07282 (2022).\n- [65] T. Skovhus, T. Olsen, arXiv:2203.04796 (2022).\n- [66] M. Gokhale, A. Ormeci, D. Mills, Phys. Rev. B 46 (1992) 8978.\n- [67] Y. Saad, Iterative Methods for Sparse Linear Systems, 2nd Edition, SIAM, Philadelphia, 2003.\n- [68] M. GrÂ¨ uning, A. Marini, X. Gonze, Comput. Math. Sci. 50 (2011) 2148.\n- [69] A. Mostafazadeh, Pseudo-Hermiticity versus PT symmetry: The necessary condition for the reality of the spectrum of a non-Hermitian Hamiltonian, J. Math. Phys. 43 (2002) 205.\n- [70] GNU Autoconf: https://www.gnu.org/software/autoconf .\n- [71] CMake is an open-source, cross-platform family of tools designed to build, test and package software: https: //cmake.org/ .\n- [72] Message passing interface forum, Int. J. Supercomput. Appl. 8 (1994) 159.\n- [73] http://theossrv1.epfl.ch/Main/Pseudopotentials .\n- [74] D. Soriano, M. I. Katsnelson, J. FernÂ´ndez-Rossier, Magnetic two-dimensional chromium trihalides: A theoa retical perspective, Nano Letters 20 (9) (2020) 6225-6234.\n- [75] T. Gorni, O. Baseggio, P. Delugas, S. Baroni, I. Timrov, turboMagnon - A code for the simulation of spin-wave spectra using the Liouville-Lanczos approach to time-dependent density-functional perturbation theory, Materials Cloud Archive 2022.89 (2022), doi: 10.24435/materialscloud:6j-kd. doi:10.24435/materialscloud: 6j-kd .\n- URL https://archive.materialscloud.org/record/2022.89\n- [76] J. Goldstone, A. Salam, S. Weinberg, Broken symmetries, Phys. Rev. 127 (1962) 965-970.\n- [77] H. Watanabe, H. Murayama, Unified description of nambu-goldstone bosons without lorentz invariance, Phys. Rev. Lett. 108 (2012) 251602.\n- [78] P. Delugas, O. Baseggio, I. Timrov, S. Baroni, T. Gorni, Magnon-phonon interactions open a gap at the Dirac point in the spin-wave spectra of CrI 3 2D magnets, submitted (arXiv:2203.01120) (2021).\n- [79] L. Chen, J.-H. Chung, B. Gao, T. Chen, M. B. Stone, A. I. Kolesnikov, Q. Huang, P. Dai, Topological spin excitations in honeycomb ferromagnet CrI , Phys. Rev. X 8 (4) (2018) 041028. 3\n- [80] L. Chen, J.-H. Chung, T. Chen, C. Duan, A. Schneidewind, I. Radelytskyi, D. J. Voneshen, R. A. Ewings, M. B. Stone, A. I. Kolesnikov, B. Winn, S. Chi, R. A. Mole, D. H. Yu, B. Gao, P. Dai, Magnetic anisotropy in ferromagnetic CrI 3 , Phys. Rev. B 101 (2020) 134418.\n- [81] L. Del Re, A. Toschi, Dynamical vertex approximation for many-electron systems with spontaneously broken su(2) symmetry, Phys. Rev. B 104 (2021) 085120.\n- [82] G. Giuliani, G. Vignale, Quantum theory of the electron liquid, Cambridge university press, 2005.\n- [83] Description of the 'Galileo100' HPC cluster at CINECA: https://www.hpc.cineca.it/hardware/ galileo100 .\n- [84] H. Monkhorst, J. Pack, Special points for Brillouin-zone integrations, Phys. Rev. B 13 (1976) 5188.\n- [85] The latest development version of the Quantum ESPRESSO distribution can be downloaded from https: //gitlab.com/QEF/q-e .\n- [86] The official release of the Quantum ESPRESSO distribution can be downloaded from https://www. quantum-espresso.org .\n## Molecular property prediction with photonic chip-based machine learning\nHui Zhang, 1, âˆ— Jonathan Wei Zhong Lau, 2, âˆ— Lingxiao Wan, 3 Liang Shi, 4 Yuzhi Shi, 5 Hong Cai, 6 Xianshu Luo, 7 Guo-Qiang Lo, 7 Chee-Kong Lee, 8, â€  Leong Chuan Kwek, 3,9,10,11, â€  and Ai Qun Liu 3, â€ \n\n### **å‚è€ƒæ–‡çŒ®**\n[1] A_photonic_chip-based_machine_learning_approach_for_the_prediction_of_molecular_properties - https://arxiv.org/abs/2203.02285\n[2] A_gentle_introduction_to_Quantum_Natural_Language_Processing - https://arxiv.org/abs/2202.11766\n[3] turboMagnon_--_A_code_for_the_simulation_of_spin-wave_spectra_using_the_Liouville-Lanczos_approach_to_time-dependent_density-functional_perturbation_theory - https://arxiv.org/abs/2203.01120\n[4] Machine_Learning_Wavefunction - https://arxiv.org/abs/2202.13916\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nç¡¼æºæ‚é‡‘åˆšçŸ³çš„çº³ç±³ç»“æ„å›¾è¡¨ï¼ˆå¦‚é€å°„ç”µé•œå›¾åƒï¼‰æ˜¯å¦èƒ½ç›´æ¥è§‚å¯Ÿåˆ°é‡å­é™åŸŸæ•ˆåº”ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\näºŒç»´ææ–™çš„èŒƒå¾·åå¼‚è´¨ç»“ç•Œé¢åœ¨å›¾è¡¨ä¸­å¦‚ä½•è¡¨å¾ï¼Ÿç•Œé¢è´¨é‡å¯¹é‡å­æ¯”ç‰¹ç›¸å¹²æ€§çš„å½±å“å¦‚ä½•é‡åŒ–ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nææ–™çš„å£°å­è°±å›¾è¡¨ï¼ˆå¦‚æ‹‰æ›¼å…‰è°±ï¼‰å¦‚ä½•å¸®åŠ©è®¾è®¡æŠ—å£°å­å™ªå£°çš„é‡å­å™¨ä»¶ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç”µè·¯æ¨¡æ‹Ÿå™¨çš„è¾“å‡ºå›¾è¡¨ï¼ˆå¦‚é‡å­æ€çš„æ—¶é—´æ¼”åŒ–ï¼‰å¦‚ä½•è¾…åŠ©è°ƒè¯•é—¨æ“ä½œè¯¯å·®ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nå¼€æ”¾é‡å­ç³»ç»Ÿçš„ä¸»æ–¹ç¨‹æ¨¡æ‹Ÿç»“æœå¦‚ä½•é€šè¿‡å›¾è¡¨å¯¹æ¯”å®éªŒæ•°æ®ï¼Ÿä¾‹å¦‚ï¼Œé€€ç›¸å¹²é€Ÿç‡çš„æ‹Ÿåˆæ›²çº¿ã€‚\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n## 4. Integration cycles in two dimensions\n\nLet us consider the following straightforward extension of the model (6) to two degrees of freedom, ğ‘§ 1 and ğ‘§ 2:\n\n$$S = \\frac { \\lambda _ { l } } { 4 } ( z _ { 1 } ^ { 2 } + z _ { 2 }$$\nwhere we once more parametrize ğœ† ğ‘™ as in (6). The concept of integration cycles is generalized to ğ‘‘ dimensions rather straightforwardly as ğ‘‘ -dimensional integration paths in C ğ‘‘ that either connect two distinct zeros of ğ‘’ -ğ‘† or are closed and incontractible. As before, in the model (10) we do not need to worry about the latter, nor about finite zeros, as ğ‘’ -ğ‘† has no singularities and only vanishes as | ğ‘§ ğ‘– | â†’âˆ . In particular, there are zeros whenever Re ğ‘† â†’âˆ as | ğ‘§ ğ‘– | â†’âˆ . To find the independent integration cycles of (10), we shall first determine these zeros.\nIntroducing the real and imaginary parts of ğ‘§ ğ‘– as ğ‘§ ğ‘– = ğ‘¥ ğ‘– + i ğ‘¦ ğ‘– , we choose the following -\nFigure 2: Sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in (12) in the ( Î” ğœ™, ğœ“ ) plane. In the shaded regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0, such that ğ‘’ -ğ‘† vanishes in the limit ğ‘Ÿ â†’âˆ , while in the white regions ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) â‰¤ 0. The real and imaginary integration cycles in these coordinates are marked as full and dashed lines, respectively.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\næœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒæŸå¤±å‡½æ•°çš„ä¸‹é™æ›²çº¿å¦‚ä½•æŒ‡å¯¼é‡å­çº é”™ç çš„ä¼˜åŒ–ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­è®¡ç®—èµ„æºä¼°ç®—å›¾è¡¨ï¼ˆå¦‚æ‰€éœ€ç‰©ç†æ¯”ç‰¹æ•°ä¸é€»è¾‘é—¨æ·±åº¦çš„å…³ç³»ï¼‰å¦‚ä½•å½±å“ç¡¬ä»¶è®¾è®¡å†³ç­–ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ç‚¹ç³»ç»Ÿä¸­ï¼Œæ …æç”µå‹è°ƒæ§çš„å›¾è¡¨å¦‚ä½•å¸®åŠ©å®ç°ç²¾ç¡®çš„é‡å­æ¯”ç‰¹è€¦åˆï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nä¸­æ€§åŸå­é˜µåˆ—çš„å…‰é•Šæ•è·æ•ˆç‡å›¾è¡¨å¦‚ä½•ä¼˜åŒ–çº ç¼ æ€åˆ¶å¤‡çš„ä¿çœŸåº¦ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\nè¶…å¯¼é‡å­ç”µè·¯çš„é¢‘ç‡æ¢³å›¾è¡¨å¦‚ä½•è¾…åŠ©æ ¡å‡†é‡å­æ¯”ç‰¹çš„å…±æŒ¯é¢‘ç‡ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\nwith Î³ = 1 2 and âˆ† = 2 . In PauliStrings.jl we can build this Hamiltonian as follows:\n\nâ˜\n\nwhere the modulo ensure periodic boundary conditions.\n```\nâœ function XXZnnn(N::Int) âˆ† = 2 Î³ = 1/2 H = ps.Operator(N) for j in 1:N H += \"X\",j, \"X\",j%N+1 H += \"Y\",j, \"Y\",j%N+1 H += âˆ† , \"Z\",j, \"Z\",j%N+1 H += Î³ , \"X\",j, \"X\",(j+1)%N+1 H += Î³ , \"Y\",j, \"Y\",(j+1)%N+1 H += Î³ * âˆ† , \"Z\",j, \"Z\",(j+1)%N+1 end return H end âœ\n```\nâœ†\nIt is known to be difficult to numerically recover the hydrodynamic diffusive behavior of strongly coupled spin chains, with some of the best current methods being the truncated Wigner approximations [24, 25] and TEBD [26]. Diffusion can be observed as a âˆ¼ 1 âˆš t decay of the infinite-temperature autocorrelation function:\n$$S ( t ) = \\frac { 1 } { 2 ^ { N } } \\, \\mathrm T r [ Z _ { 1 } ( t ) Z _ { 1 } ( 0 ) ]. \\quad \\quad \\quad ( 1 6 )$$\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[2] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
{"prompt": "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n\n**ç”¨æˆ·é—®é¢˜ï¼š**\né‡å­ - ç»å…¸æ··åˆç³»ç»Ÿçš„æ¥å£è®¾è®¡å›¾è¡¨ï¼ˆå¦‚é‡‘åˆšçŸ³è‰²å¿ƒä¸å¾®æ³¢è…”çš„è€¦åˆï¼‰å¦‚ä½•å¹³è¡¡é‡å­ç‰¹æ€§ä¸ç»å…¸æ§åˆ¶ï¼Ÿ\n\n**ä¸Šä¸‹æ–‡ï¼š**\nTo extract such information, a multicontrolled NOT gate is applied targeting an ancillary qubit. Note that only the basis state | N - ã€‰ 1 in the superposition flips the ancilla to the state | 1 . ã€‰ Consequently, the final quantum state | Ïˆ f ã€‰ is:\n$$| \\psi _ { f } \\rangle = c _ { 0 } \\, | 0 \\rangle \\, | 0 \\rangle + c _ { 1 } \\, | 1 \\rangle \\, | 0 \\rangle + \\cdots \\\\ + c _ { N - 2 } \\, | N - 2 \\rangle \\, | 0 \\rangle + \\langle \\psi _ { w } | \\psi _ { i } \\rangle \\, | N - 1 \\rangle \\, | 1 \\rangle \\,.$$\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\n\nâœ¤\nSince ã€ˆ Ïˆ w | Ïˆ i ã€‰ = /vector w âˆ— Â· /vector i , measuring that ancillary qubit finally gives the activation function already presented in (3). Therefore, that quantum neuron framework applies the kernel trick and activates following a non-deterministic function of the computed inner product, which was to be shown. To instantiate a quantum neuron, one only needs to realize a feature mapping Î¦( ) by Â· means of the operators E and D .\n## 2.1 Binary-Valued Quantum Neuron\nThe following is a code example of noisy time evolution implementation in PauliStrings.jl used to generate Fig. 1:\n```\nâœ # heisenberg evolution of the operator O using rk4 # return tr(O(0)*O(t))/tr(O(t)^2) # M is the number of strings to keep at each step # noise is the amplitude of depolarizing noise function evolve(H, O, M, times, noise) S = [] O0 = deepcopy(O) dt = times[2]-times[1] for t in times push!(S, ps.trace(O*ps.dagger(O0))/ps.trace(O0*O0)) #preform one step of rk4, keep only M strings, do not discard O0 O = ps.rk4(H, O, dt; heisenberg=true, M=M, keep=O0) #add depolarizing noise O = ps.add_noise(O, noise*dt) # keep the M strings with the largest weight. Do not discard O0 O = ps.trim(O, M; keep=O0) end return real.(S) end âœ\n```\nâ˜\n\nâœ†\nAchieving time evolution at this system size with dense or sparse matrices would require a large amount of distributed memory, making it very computationally expensive to run. On the other hand, using TEBD as shown in Fig. 4 we are able to get converged results with 9 Gb of memory but only up to t âˆ¼ 1 in 4 days runtime. The PauliStrings.jl result with M = 2 18 and Ïµ = 0 01 . is shown for comparison and displays the expected decay to an order of magnitude longer time ( t âˆ¼ 10 ), though it only required 5 Gb of memory and 1 day of runtime. The TEBD results shown use a truncation cutoff of 10 -10 ; we also performed the same simulation for both larger and smaller\ncutoffs, but found 10 -10 to be more than sufficiently converged while larger cutoffs did not improve accessible simulation times without significant loss of accuracy. Thus PauliStrings.jl performs significantly better than TEBD for Heisenberg time evolution of the next-nearest neighbor XXZ chain.\n![Image](https://serverip/images/Kernels_and_integration_cycles_in_complex_Langevin_simulations-with-image-refs_artifacts/image_000003_d83dbf800617ef4b9103869efbe05c697f02f1ba1917a026522a0de5670d09ce.png)\n\nconvenient, but perhaps unusual - parametrization:\n$$x _ { 1 } = r _ { x } \\cos ( \\phi _ { x } ) \\, \\ \\ x _ { 2 } = r _ { x } \\sin ( \\phi _ { x } ) \\, \\ \\ r _ { x } = r \\cos ( \\psi ) \\, \\ \\ y _ { 1 } = r _ { y } \\cos ( \\phi _ { y } ) \\, \\ \\ y _ { 2 } = r _ { y } \\sin ( \\phi _ { y } ) \\, \\ \\ r _ { y } = r \\sin ( \\psi )$$\nsuch that ğœ“ = arctan GLYPH&lt;16&gt; ğ‘Ÿ ğ‘¦ ğ‘Ÿ ğ‘¥ GLYPH&lt;17&gt; âˆˆ GLYPH&lt;2&gt; 0 , ğœ‹ 2 GLYPH&lt;3&gt; . Inserting (11) back into (10), we obtain the following expression for the real part of ğ‘† , again assuming ğœ† ğ‘™ = 1 without loss of generality:\n$$R e \\, S = r ^ { 4 } P ( \\phi _ { x }, \\phi _ { y }, \\psi ) \\,, \\ \\ P ( \\phi _ { x }, \\phi _ { y }, \\psi ) = \\cos ^ { 2 } ( 2 \\psi ) - \\sin ^ { 2 } ( 2 \\psi ) \\cos ^ { 2 } ( \\phi _ { x } - \\phi _ { y } ) \\,. \\quad ( 1 2 )$$\nNotice how the latter expression depends only on the difference Î” ğœ™ : = ğœ™ ğ‘¥ -ğœ™ ğ‘¦ , which nicely reflects the O 2 ( ) symmetry of (10). We have thus reduced the problem of finding the zeros of ğ‘’ -ğ‘† to the problem of finding regions in ( Î” ğœ™, ğœ“ ) space where ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) &gt; 0. We show a plot of the sign of ğ‘ƒ ğœ™ , ğœ™ ( ğ‘¥ ğ‘¦ , ğœ“ ) in Fig. 2.\n\n### **å‚è€ƒæ–‡çŒ®**\n[1] Kernels_and_integration_cycles_in_complex_Langevin_simulations - https://arxiv.org/abs/2410.13423\n[2] Quantum_many-body_simulations_with_PauliStrings.jl - https://arxiv.org/abs/2410.09654\n[3] Parametrized_constant-depth_quantum_neuron - https://arxiv.org/abs/2202.12496\n\nè¯·æä¾›ä¸€ä¸ªä¸“ä¸šæ€§çš„å›ç­”ã€‚", "completion": ""}
